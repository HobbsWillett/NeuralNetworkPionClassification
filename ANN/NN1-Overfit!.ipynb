{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Version , oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.900745391845703 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import time\n",
    "start_time = time.time()\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.metrics import binary_accuracy\n",
    "#from keras.utils import np_utils\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.035631418228149414 seconds ---\n",
      "(247, 21)\n",
      "--- 1.7535533905029297 seconds ---\n",
      "(46280, 21)\n",
      " FirstLayer  LastLayer NHits  AverageZP Thrust  PID_Angle  PID_Front  PID_LLR_M  FirstLayer  LastLayer  NHits_Low  AverageZP  Thrust_Lo  PID_Angle  PID_Front  PID_LLR_M  Energy_As  Angle_Bet  Distance_Bet   Sig   Bg\n"
     ]
    }
   ],
   "source": [
    "# import datasets with time taken!\n",
    "#smoll\n",
    "start_time = time.time()\n",
    "smoll = np.loadtxt(\"/home/willett/NeutrinoData/small_CNN_input_processed.txt\", comments='#')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(smoll.shape)\n",
    "\n",
    "\n",
    "#and the full\n",
    "start_time = time.time()\n",
    "fll = np.loadtxt(\"/home/willett/NeutrinoData/full_CNN_input_processed.txt\", comments='#')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(fll.shape)\n",
    "\n",
    "\n",
    "\"\"\" # commented out to save computation\n",
    "#and the full\n",
    "start_time = time.time()\n",
    "fll = np.loadtxt(\"/home/willett/NeutrinoData/test_CNN_input_processed.txt\", comments='#')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(fll.shape)\n",
    "\"\"\"\n",
    "\n",
    "# extract title\n",
    "pls = open(\"/home/willett/NeutrinoData/small_CNN_input_processed.txt\", \"r\")\n",
    "title = pls.readline()\n",
    "title = title[2:-1]\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (247, 21) \n",
      "size:  5187  \n",
      "length:  247\n"
     ]
    }
   ],
   "source": [
    "# creating a dataset switch, change what UsedData is to change CNN\n",
    "UD = smoll # Used Data = <dataset>\n",
    "UDLength = UD.shape[0]\n",
    "print(\"shape: \",UD.shape,\"\\nsize: \", UD.size,\" \\nlength: \", UDLength)\n",
    "\n",
    "# dataset is expected in this format:\n",
    "# FirstLayer  LastLayer NHits  AverageZP Thrust  PID_Angle  PID_Front  PID_LLR_M\n",
    "#FirstLayer  LastLayer  NHits_Low  AverageZP  Thrust_Lo  PID_Angle  PID_Front  PID_LLR_M  \n",
    "#Energy_As  Angle_Bet  Distance_Bet   Sig   Bg\n",
    "\n",
    "# with Sig and Bg expected as one hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (247, 19) \n",
      "Y shape:  (247, 2)\n"
     ]
    }
   ],
   "source": [
    "# splitting X = dataset , Y = one hot vectors\n",
    "X = UD[:,0:-2]\n",
    "Y = UD[:,-2:1000]\n",
    "print(\"X shape: \",X.shape,\"\\nY shape: \", Y.shape)\n",
    "\n",
    "# they will be split into testing and training at compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " signal and background event number:  10 237 \n",
      " number more needed: 23\n",
      "initial Signal to Noise ratio:  4.048582995951417 % signal\n",
      "(230, 19) (230, 2)\n",
      "(467, 19) (467, 2)\n",
      "these arrays should be different vertically, to ensure shuffle succesful:\n",
      "[0.00829848 0.0039091  0.00049919] [0. 0. 0.]\n",
      "[0.00023506 0.00193593 0.00247473] [0. 1. 1.]\n",
      "final Signal Noise ratio:  49.25053533190578 % signal\n",
      "--- 0.024544239044189453 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# inevitable bias removal... by oversampling\n",
    "# using a 50% oversampling ratio, because i want to ! (no citation)\n",
    "\n",
    "#how long?\n",
    "start_time = time.time()\n",
    "\n",
    "SigI = np.where(Y[:,0] == 1)[0] \n",
    "BgI= np.where(Y[:,0] == 0)[0]\n",
    "SigN = SigI.size       # how much signal there is\n",
    "BgN = BgI.size         # how much background there is\n",
    "Multip = int(BgN/SigN) # how much more signal event copies needed for ~50%\n",
    "print(\" signal and background event number: \",SigI.size,BgI.size,\"\\n number more needed:\",Multip)\n",
    "SNratio =  (100*SigN)/(SigN + BgN)\n",
    "print(\"initial Signal to Noise ratio: \",SNratio,\"% signal\")\n",
    "\n",
    "#im going to reconstruct the arrays of signal events, background events, then add them together and shuffle!\n",
    "\n",
    "XSig = X[SigI]\n",
    "XBg = X[BgI]\n",
    "YSig = Y[SigI]\n",
    "YBg = Y[BgI]\n",
    "#print(XSig.shape,XBg.shape, YSig.shape, YBg.shape) # these are the events of each type.\n",
    "\n",
    "# this is the array of signal repreated (tiled) multip times.\n",
    "YSigM = np.transpose(np.tile(np.transpose(YSig), Multip))\n",
    "XSigM = np.transpose(np.tile(np.transpose(XSig), Multip)) \n",
    "print( XSigM.shape, YSigM.shape)\n",
    "\n",
    "#adding arrays together and then shuffling:\n",
    "X2 = np.concatenate((XBg,XSigM))\n",
    "Y2 = np.concatenate((YBg,YSigM))\n",
    "print(X2.shape, Y2.shape)\n",
    "\n",
    "#shuffling\n",
    "print(\"these arrays should be different vertically, to ensure shuffle succesful:\")\n",
    "print(X2[0:3,0],Y2[0:3,0])\n",
    "np.random.shuffle(X2)\n",
    "np.random.shuffle(Y2)\n",
    "print(X2[0:3,0],Y2[0:3,0])\n",
    "\n",
    "#final ratio:\n",
    "NewSigN = YSigM.shape[0]\n",
    "SNRatioNew = (100*YSigM.shape[0]) / (YSigM.shape[0] + BgN)\n",
    "print(\"final Signal Noise ratio: \",SNRatioNew,\"% signal\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467, 19)\n",
      "(467, 19, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X2.shape)\n",
    "X3 = np.expand_dims(X2, axis=2)\n",
    "print(X3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.26398801803588867 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#neural network architecture:\n",
    "model = Sequential()\n",
    "\n",
    "# set variables:\n",
    "width = 8 #--number on nodes in the layer\n",
    "DR = 0.5 #--fraction of nodes dropped during training\n",
    "AT = \"sigmoid\" #--activation type for dense layers\n",
    "UB = True #--use bias vectors \n",
    "InDim = (X3.shape[1],X3.shape[2] ) #--input shape of single sample (tuple)\n",
    "\n",
    "#construction:\n",
    "start_time = time.time() # how long does it take?\n",
    "model.add(Dense(width,activation=AT, use_bias=UB, input_shape=(19,1) )) # input layer and 1\n",
    "model.add(Dropout(DR))\n",
    "model.add(Dense(width,activation=AT, use_bias=UB )) # 2\n",
    "model.add(Dropout(DR))\n",
    "model.add(Dense(width,activation=AT, use_bias=UB )) # 3\n",
    "model.add(Dropout(DR))\n",
    "model.add(Dense(width,activation=AT, use_bias=UB )) # 4\n",
    "model.add(Dropout(DR))\n",
    "\n",
    "model.add(Flatten())  # reduce dimensionality of the input data for output\n",
    "\n",
    "model.add(Dense(2, activation=\"softmax\", use_bias=UB)) # output layer softmax recommended \n",
    "#(classification mutually excluive + softmax differentiable for optimizing)\n",
    "# -> https://www.quora.com/Artificial-Neural-Networks-Why-do-we-use-softmax-function-for-output-layer\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regularizer if overfitting! ^\n",
    "\n",
    "# binary_crossentropy is the best according to https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/\n",
    "# adam is best for me according to https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.05253148078918457 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# compile model:\n",
    "start_time = time.time() # how long does it take?\n",
    "model.compile(optimizer='adadelta',            \n",
    "              loss='binary_crossentropy',               \n",
    "              metrics=['accuracy', 'binary_accuracy' ])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.6934 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 2/1000\n",
      "420/420 [==============================] - 0s 239us/step - loss: 0.6940 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 3/1000\n",
      "420/420 [==============================] - 0s 230us/step - loss: 0.6934 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 4/1000\n",
      "420/420 [==============================] - 0s 182us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 5/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6938 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 6/1000\n",
      "420/420 [==============================] - 0s 148us/step - loss: 0.6934 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 7/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6937 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 8/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6931 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 9/1000\n",
      "420/420 [==============================] - 0s 150us/step - loss: 0.6926 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 10/1000\n",
      "420/420 [==============================] - 0s 182us/step - loss: 0.6936 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 11/1000\n",
      "420/420 [==============================] - 0s 192us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 12/1000\n",
      "420/420 [==============================] - 0s 252us/step - loss: 0.6931 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 13/1000\n",
      "420/420 [==============================] - 0s 335us/step - loss: 0.6923 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 14/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6937 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 15/1000\n",
      "420/420 [==============================] - 0s 330us/step - loss: 0.6934 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 16/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6923 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 17/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6932 - acc: 0.5381 - binary_accuracy: 0.5381 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 18/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 19/1000\n",
      "420/420 [==============================] - 0s 276us/step - loss: 0.6930 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 20/1000\n",
      "420/420 [==============================] - 0s 271us/step - loss: 0.6934 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 21/1000\n",
      "420/420 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 22/1000\n",
      "420/420 [==============================] - 0s 295us/step - loss: 0.6929 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 23/1000\n",
      "420/420 [==============================] - 0s 285us/step - loss: 0.6934 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 24/1000\n",
      "420/420 [==============================] - 0s 211us/step - loss: 0.6933 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 25/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6939 - acc: 0.5060 - binary_accuracy: 0.5060 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 26/1000\n",
      "420/420 [==============================] - 0s 173us/step - loss: 0.6938 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 27/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6938 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 28/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6929 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 29/1000\n",
      "420/420 [==============================] - 0s 254us/step - loss: 0.6931 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 30/1000\n",
      "420/420 [==============================] - 0s 283us/step - loss: 0.6932 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 31/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6933 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 32/1000\n",
      "420/420 [==============================] - 0s 232us/step - loss: 0.6937 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 33/1000\n",
      "420/420 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 34/1000\n",
      "420/420 [==============================] - 0s 260us/step - loss: 0.6932 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 35/1000\n",
      "420/420 [==============================] - 0s 284us/step - loss: 0.6932 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 36/1000\n",
      "420/420 [==============================] - 0s 249us/step - loss: 0.6936 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 37/1000\n",
      "420/420 [==============================] - 0s 249us/step - loss: 0.6928 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 38/1000\n",
      "420/420 [==============================] - 0s 255us/step - loss: 0.6938 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 39/1000\n",
      "420/420 [==============================] - 0s 276us/step - loss: 0.6941 - acc: 0.4798 - binary_accuracy: 0.4798 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 40/1000\n",
      "420/420 [==============================] - 0s 223us/step - loss: 0.6927 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 41/1000\n",
      "420/420 [==============================] - 0s 224us/step - loss: 0.6934 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 42/1000\n",
      "420/420 [==============================] - 0s 219us/step - loss: 0.6940 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 195us/step - loss: 0.6931 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 44/1000\n",
      "420/420 [==============================] - 0s 241us/step - loss: 0.6927 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 45/1000\n",
      "420/420 [==============================] - 0s 257us/step - loss: 0.6932 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 46/1000\n",
      "420/420 [==============================] - 0s 278us/step - loss: 0.6934 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 47/1000\n",
      "420/420 [==============================] - 0s 287us/step - loss: 0.6932 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 48/1000\n",
      "420/420 [==============================] - 0s 276us/step - loss: 0.6930 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 49/1000\n",
      "420/420 [==============================] - 0s 211us/step - loss: 0.6943 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 50/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6934 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 51/1000\n",
      "420/420 [==============================] - 0s 315us/step - loss: 0.6928 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 52/1000\n",
      "420/420 [==============================] - 0s 263us/step - loss: 0.6946 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 53/1000\n",
      "420/420 [==============================] - 0s 209us/step - loss: 0.6928 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 54/1000\n",
      "420/420 [==============================] - 0s 216us/step - loss: 0.6935 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 55/1000\n",
      "420/420 [==============================] - 0s 299us/step - loss: 0.6927 - acc: 0.5452 - binary_accuracy: 0.5452 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 56/1000\n",
      "420/420 [==============================] - 0s 267us/step - loss: 0.6933 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 57/1000\n",
      "420/420 [==============================] - 0s 305us/step - loss: 0.6930 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 58/1000\n",
      "420/420 [==============================] - 0s 285us/step - loss: 0.6922 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 59/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6932 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 60/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6941 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 61/1000\n",
      "420/420 [==============================] - 0s 161us/step - loss: 0.6921 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 62/1000\n",
      "420/420 [==============================] - 0s 187us/step - loss: 0.6931 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 63/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6931 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 64/1000\n",
      "420/420 [==============================] - 0s 161us/step - loss: 0.6923 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 65/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6941 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 66/1000\n",
      "420/420 [==============================] - 0s 150us/step - loss: 0.6926 - acc: 0.5405 - binary_accuracy: 0.5405 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 67/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6937 - acc: 0.5524 - binary_accuracy: 0.5524 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 68/1000\n",
      "420/420 [==============================] - 0s 116us/step - loss: 0.6938 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 69/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6941 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 70/1000\n",
      "420/420 [==============================] - 0s 190us/step - loss: 0.6927 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 71/1000\n",
      "420/420 [==============================] - 0s 204us/step - loss: 0.6936 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 72/1000\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.6927 - acc: 0.5381 - binary_accuracy: 0.5381 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 73/1000\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.6932 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 74/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6931 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 75/1000\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.6936 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 76/1000\n",
      "420/420 [==============================] - 0s 153us/step - loss: 0.6942 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 77/1000\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.6934 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 78/1000\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.6938 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 79/1000\n",
      "420/420 [==============================] - 0s 196us/step - loss: 0.6928 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 80/1000\n",
      "420/420 [==============================] - 0s 224us/step - loss: 0.6937 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 81/1000\n",
      "420/420 [==============================] - 0s 203us/step - loss: 0.6940 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 82/1000\n",
      "420/420 [==============================] - 0s 228us/step - loss: 0.6942 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 83/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6938 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 84/1000\n",
      "420/420 [==============================] - 0s 219us/step - loss: 0.6942 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 233us/step - loss: 0.6927 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 86/1000\n",
      "420/420 [==============================] - 0s 222us/step - loss: 0.6937 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 87/1000\n",
      "420/420 [==============================] - 0s 206us/step - loss: 0.6937 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 88/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6925 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 89/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6936 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 90/1000\n",
      "420/420 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 91/1000\n",
      "420/420 [==============================] - 0s 166us/step - loss: 0.6934 - acc: 0.4571 - binary_accuracy: 0.4571 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 92/1000\n",
      "420/420 [==============================] - 0s 116us/step - loss: 0.6932 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 93/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6928 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 94/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6934 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 95/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6922 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 96/1000\n",
      "420/420 [==============================] - 0s 144us/step - loss: 0.6931 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 97/1000\n",
      "420/420 [==============================] - 0s 146us/step - loss: 0.6929 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 98/1000\n",
      "420/420 [==============================] - 0s 184us/step - loss: 0.6933 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 99/1000\n",
      "420/420 [==============================] - 0s 186us/step - loss: 0.6915 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 100/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6928 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 101/1000\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.6933 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 102/1000\n",
      "420/420 [==============================] - 0s 221us/step - loss: 0.6939 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 103/1000\n",
      "420/420 [==============================] - 0s 249us/step - loss: 0.6934 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 104/1000\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.6941 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 105/1000\n",
      "420/420 [==============================] - 0s 158us/step - loss: 0.6930 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 106/1000\n",
      "420/420 [==============================] - 0s 185us/step - loss: 0.6936 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 107/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6933 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 108/1000\n",
      "420/420 [==============================] - 0s 153us/step - loss: 0.6934 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 109/1000\n",
      "420/420 [==============================] - 0s 168us/step - loss: 0.6927 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 110/1000\n",
      "420/420 [==============================] - 0s 161us/step - loss: 0.6932 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 111/1000\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.6936 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 112/1000\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.6934 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6931 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 113/1000\n",
      "420/420 [==============================] - 0s 290us/step - loss: 0.6935 - acc: 0.4964 - binary_accuracy: 0.4964 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 114/1000\n",
      "420/420 [==============================] - 0s 227us/step - loss: 0.6943 - acc: 0.4429 - binary_accuracy: 0.4429 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 115/1000\n",
      "420/420 [==============================] - 0s 183us/step - loss: 0.6940 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 116/1000\n",
      "420/420 [==============================] - 0s 161us/step - loss: 0.6932 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 117/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6929 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 118/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6930 - acc: 0.5381 - binary_accuracy: 0.5381 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 119/1000\n",
      "420/420 [==============================] - 0s 187us/step - loss: 0.6933 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 120/1000\n",
      "420/420 [==============================] - 0s 210us/step - loss: 0.6932 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 121/1000\n",
      "420/420 [==============================] - 0s 183us/step - loss: 0.6938 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 122/1000\n",
      "420/420 [==============================] - 0s 216us/step - loss: 0.6931 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 123/1000\n",
      "420/420 [==============================] - 0s 220us/step - loss: 0.6940 - acc: 0.4571 - binary_accuracy: 0.4571 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 124/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6930 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 125/1000\n",
      "420/420 [==============================] - 0s 264us/step - loss: 0.6932 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 126/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6927 - acc: 0.5381 - binary_accuracy: 0.5381 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 127/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 208us/step - loss: 0.6934 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 128/1000\n",
      "420/420 [==============================] - 0s 230us/step - loss: 0.6927 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 129/1000\n",
      "420/420 [==============================] - 0s 215us/step - loss: 0.6937 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 130/1000\n",
      "420/420 [==============================] - 0s 259us/step - loss: 0.6928 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 131/1000\n",
      "420/420 [==============================] - 0s 243us/step - loss: 0.6933 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 132/1000\n",
      "420/420 [==============================] - 0s 153us/step - loss: 0.6932 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 133/1000\n",
      "420/420 [==============================] - 0s 191us/step - loss: 0.6940 - acc: 0.4571 - binary_accuracy: 0.4571 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 134/1000\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.6931 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 135/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6932 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 136/1000\n",
      "420/420 [==============================] - 0s 184us/step - loss: 0.6932 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 137/1000\n",
      "420/420 [==============================] - 0s 204us/step - loss: 0.6933 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 138/1000\n",
      "420/420 [==============================] - 0s 237us/step - loss: 0.6930 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 139/1000\n",
      "420/420 [==============================] - 0s 267us/step - loss: 0.6928 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 140/1000\n",
      "420/420 [==============================] - 0s 322us/step - loss: 0.6938 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 141/1000\n",
      "420/420 [==============================] - 0s 297us/step - loss: 0.6932 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 142/1000\n",
      "420/420 [==============================] - 0s 213us/step - loss: 0.6931 - acc: 0.5381 - binary_accuracy: 0.5381 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 143/1000\n",
      "420/420 [==============================] - 0s 264us/step - loss: 0.6928 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 144/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6927 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 145/1000\n",
      "420/420 [==============================] - 0s 348us/step - loss: 0.6930 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 146/1000\n",
      "420/420 [==============================] - 0s 269us/step - loss: 0.6941 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 147/1000\n",
      "420/420 [==============================] - 0s 209us/step - loss: 0.6936 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 148/1000\n",
      "420/420 [==============================] - 0s 206us/step - loss: 0.6938 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 149/1000\n",
      "420/420 [==============================] - 0s 233us/step - loss: 0.6933 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 150/1000\n",
      "420/420 [==============================] - 0s 320us/step - loss: 0.6931 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 151/1000\n",
      "420/420 [==============================] - 0s 322us/step - loss: 0.6933 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6942 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 152/1000\n",
      "420/420 [==============================] - 0s 291us/step - loss: 0.6930 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 153/1000\n",
      "420/420 [==============================] - 0s 252us/step - loss: 0.6925 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 154/1000\n",
      "420/420 [==============================] - 0s 319us/step - loss: 0.6929 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 155/1000\n",
      "420/420 [==============================] - 0s 262us/step - loss: 0.6927 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 156/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6941 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 157/1000\n",
      "420/420 [==============================] - 0s 229us/step - loss: 0.6920 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6948 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 158/1000\n",
      "420/420 [==============================] - 0s 203us/step - loss: 0.6932 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 159/1000\n",
      "420/420 [==============================] - 0s 135us/step - loss: 0.6929 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 160/1000\n",
      "420/420 [==============================] - 0s 177us/step - loss: 0.6928 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 161/1000\n",
      "420/420 [==============================] - 0s 187us/step - loss: 0.6928 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 162/1000\n",
      "420/420 [==============================] - 0s 251us/step - loss: 0.6930 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 163/1000\n",
      "420/420 [==============================] - 0s 318us/step - loss: 0.6940 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6942 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 164/1000\n",
      "420/420 [==============================] - 0s 240us/step - loss: 0.6938 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6946 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 165/1000\n",
      "420/420 [==============================] - 0s 213us/step - loss: 0.6931 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6942 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 166/1000\n",
      "420/420 [==============================] - 0s 192us/step - loss: 0.6935 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6942 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 167/1000\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.6934 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 168/1000\n",
      "420/420 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 216us/step - loss: 0.6936 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 170/1000\n",
      "420/420 [==============================] - 0s 220us/step - loss: 0.6929 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 171/1000\n",
      "420/420 [==============================] - 0s 301us/step - loss: 0.6925 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 172/1000\n",
      "420/420 [==============================] - 0s 307us/step - loss: 0.6925 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 173/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6928 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 174/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6941 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 175/1000\n",
      "420/420 [==============================] - 0s 292us/step - loss: 0.6933 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 176/1000\n",
      "420/420 [==============================] - 0s 278us/step - loss: 0.6925 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 177/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6925 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 178/1000\n",
      "420/420 [==============================] - 0s 290us/step - loss: 0.6926 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 179/1000\n",
      "420/420 [==============================] - 0s 288us/step - loss: 0.6938 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 180/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6941 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 181/1000\n",
      "420/420 [==============================] - 0s 260us/step - loss: 0.6930 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 182/1000\n",
      "420/420 [==============================] - 0s 339us/step - loss: 0.6934 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 183/1000\n",
      "420/420 [==============================] - 0s 341us/step - loss: 0.6933 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 184/1000\n",
      "420/420 [==============================] - 0s 291us/step - loss: 0.6929 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 185/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6936 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 186/1000\n",
      "420/420 [==============================] - 0s 240us/step - loss: 0.6925 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 187/1000\n",
      "420/420 [==============================] - 0s 265us/step - loss: 0.6945 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 188/1000\n",
      "420/420 [==============================] - 0s 259us/step - loss: 0.6933 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 189/1000\n",
      "420/420 [==============================] - 0s 255us/step - loss: 0.6940 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 190/1000\n",
      "420/420 [==============================] - 0s 196us/step - loss: 0.6935 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 191/1000\n",
      "420/420 [==============================] - 0s 251us/step - loss: 0.6942 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 192/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6935 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 193/1000\n",
      "420/420 [==============================] - 0s 223us/step - loss: 0.6929 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 194/1000\n",
      "420/420 [==============================] - 0s 226us/step - loss: 0.6928 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 195/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6930 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 196/1000\n",
      "420/420 [==============================] - 0s 209us/step - loss: 0.6928 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 197/1000\n",
      "420/420 [==============================] - 0s 213us/step - loss: 0.6925 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 198/1000\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.6940 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 199/1000\n",
      "420/420 [==============================] - 0s 177us/step - loss: 0.6929 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 200/1000\n",
      "420/420 [==============================] - 0s 185us/step - loss: 0.6937 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 201/1000\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.6933 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 202/1000\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.6925 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 203/1000\n",
      "420/420 [==============================] - 0s 170us/step - loss: 0.6929 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 204/1000\n",
      "420/420 [==============================] - 0s 165us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 205/1000\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.6923 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 206/1000\n",
      "420/420 [==============================] - 0s 285us/step - loss: 0.6936 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 207/1000\n",
      "420/420 [==============================] - 0s 222us/step - loss: 0.6928 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 208/1000\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.6940 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 209/1000\n",
      "420/420 [==============================] - 0s 146us/step - loss: 0.6939 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 210/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6931 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 123us/step - loss: 0.6927 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 212/1000\n",
      "420/420 [==============================] - 0s 120us/step - loss: 0.6927 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 213/1000\n",
      "420/420 [==============================] - 0s 120us/step - loss: 0.6934 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 214/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6927 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 215/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6945 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 216/1000\n",
      "420/420 [==============================] - 0s 134us/step - loss: 0.6933 - acc: 0.5381 - binary_accuracy: 0.5381 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 217/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6924 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 218/1000\n",
      "420/420 [==============================] - 0s 163us/step - loss: 0.6929 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 219/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6938 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 220/1000\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.6938 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 221/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6937 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 222/1000\n",
      "420/420 [==============================] - 0s 154us/step - loss: 0.6926 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 223/1000\n",
      "420/420 [==============================] - 0s 220us/step - loss: 0.6931 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 224/1000\n",
      "420/420 [==============================] - 0s 228us/step - loss: 0.6950 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 225/1000\n",
      "420/420 [==============================] - 0s 302us/step - loss: 0.6934 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 226/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6939 - acc: 0.4429 - binary_accuracy: 0.4429 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 227/1000\n",
      "420/420 [==============================] - 0s 272us/step - loss: 0.6922 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 228/1000\n",
      "420/420 [==============================] - 0s 286us/step - loss: 0.6936 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 229/1000\n",
      "420/420 [==============================] - 0s 251us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 230/1000\n",
      "420/420 [==============================] - 0s 204us/step - loss: 0.6925 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 231/1000\n",
      "420/420 [==============================] - 0s 183us/step - loss: 0.6927 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 232/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6933 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 233/1000\n",
      "420/420 [==============================] - 0s 200us/step - loss: 0.6925 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 234/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6932 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 235/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6942 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 236/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6931 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 237/1000\n",
      "420/420 [==============================] - 0s 166us/step - loss: 0.6927 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 238/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6926 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 239/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6934 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 240/1000\n",
      "420/420 [==============================] - 0s 215us/step - loss: 0.6935 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 241/1000\n",
      "420/420 [==============================] - 0s 254us/step - loss: 0.6941 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 242/1000\n",
      "420/420 [==============================] - 0s 257us/step - loss: 0.6933 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 243/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6948 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 244/1000\n",
      "420/420 [==============================] - 0s 318us/step - loss: 0.6933 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 245/1000\n",
      "420/420 [==============================] - 0s 289us/step - loss: 0.6927 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 246/1000\n",
      "420/420 [==============================] - 0s 194us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 247/1000\n",
      "420/420 [==============================] - 0s 288us/step - loss: 0.6936 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 248/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6935 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 249/1000\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.6929 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 250/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6948 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 251/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6939 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 252/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6923 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 253/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 160us/step - loss: 0.6934 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 254/1000\n",
      "420/420 [==============================] - 0s 145us/step - loss: 0.6931 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 255/1000\n",
      "420/420 [==============================] - 0s 183us/step - loss: 0.6912 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 256/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6927 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 257/1000\n",
      "420/420 [==============================] - 0s 216us/step - loss: 0.6935 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 258/1000\n",
      "420/420 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 259/1000\n",
      "420/420 [==============================] - 0s 263us/step - loss: 0.6933 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6942 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 260/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6929 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 261/1000\n",
      "420/420 [==============================] - 0s 245us/step - loss: 0.6939 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 262/1000\n",
      "420/420 [==============================] - 0s 262us/step - loss: 0.6934 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 263/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6937 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 264/1000\n",
      "420/420 [==============================] - 0s 311us/step - loss: 0.6938 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 265/1000\n",
      "420/420 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 266/1000\n",
      "420/420 [==============================] - 0s 248us/step - loss: 0.6930 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 267/1000\n",
      "420/420 [==============================] - 0s 299us/step - loss: 0.6929 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 268/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6936 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 269/1000\n",
      "420/420 [==============================] - 0s 306us/step - loss: 0.6920 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 270/1000\n",
      "420/420 [==============================] - 0s 232us/step - loss: 0.6935 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 271/1000\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.6923 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 272/1000\n",
      "420/420 [==============================] - 0s 134us/step - loss: 0.6933 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 273/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6932 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 274/1000\n",
      "420/420 [==============================] - 0s 116us/step - loss: 0.6938 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 275/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6932 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 276/1000\n",
      "420/420 [==============================] - 0s 125us/step - loss: 0.6926 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 277/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6933 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 278/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6933 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 279/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6933 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 280/1000\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.6938 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 281/1000\n",
      "420/420 [==============================] - 0s 177us/step - loss: 0.6936 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 282/1000\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.6941 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 283/1000\n",
      "420/420 [==============================] - 0s 203us/step - loss: 0.6933 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 284/1000\n",
      "420/420 [==============================] - 0s 158us/step - loss: 0.6927 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 285/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6934 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 286/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6939 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6931 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 287/1000\n",
      "420/420 [==============================] - 0s 137us/step - loss: 0.6918 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 288/1000\n",
      "420/420 [==============================] - 0s 115us/step - loss: 0.6940 - acc: 0.4524 - binary_accuracy: 0.4524 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 289/1000\n",
      "420/420 [==============================] - 0s 120us/step - loss: 0.6924 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 290/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6927 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 291/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6936 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 292/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6940 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 293/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6939 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 294/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6932 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 143us/step - loss: 0.6937 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 296/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6937 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 297/1000\n",
      "420/420 [==============================] - 0s 148us/step - loss: 0.6944 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 298/1000\n",
      "420/420 [==============================] - 0s 140us/step - loss: 0.6927 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 299/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6929 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 300/1000\n",
      "420/420 [==============================] - 0s 110us/step - loss: 0.6934 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 301/1000\n",
      "420/420 [==============================] - 0s 113us/step - loss: 0.6922 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 302/1000\n",
      "420/420 [==============================] - 0s 115us/step - loss: 0.6927 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 303/1000\n",
      "420/420 [==============================] - 0s 113us/step - loss: 0.6937 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 304/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6940 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 305/1000\n",
      "420/420 [==============================] - 0s 125us/step - loss: 0.6935 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 306/1000\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.6933 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 307/1000\n",
      "420/420 [==============================] - 0s 165us/step - loss: 0.6934 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 308/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 309/1000\n",
      "420/420 [==============================] - 0s 284us/step - loss: 0.6930 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 310/1000\n",
      "420/420 [==============================] - 0s 213us/step - loss: 0.6937 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 311/1000\n",
      "420/420 [==============================] - 0s 151us/step - loss: 0.6937 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 312/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6931 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 313/1000\n",
      "420/420 [==============================] - 0s 205us/step - loss: 0.6936 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 314/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6933 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 315/1000\n",
      "420/420 [==============================] - 0s 318us/step - loss: 0.6929 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 316/1000\n",
      "420/420 [==============================] - 0s 323us/step - loss: 0.6932 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 317/1000\n",
      "420/420 [==============================] - 0s 348us/step - loss: 0.6929 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 318/1000\n",
      "420/420 [==============================] - 0s 158us/step - loss: 0.6922 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 319/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6937 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 320/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6934 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 321/1000\n",
      "420/420 [==============================] - 0s 132us/step - loss: 0.6944 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 322/1000\n",
      "420/420 [==============================] - 0s 116us/step - loss: 0.6931 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 323/1000\n",
      "420/420 [==============================] - 0s 150us/step - loss: 0.6929 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 324/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6930 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 325/1000\n",
      "420/420 [==============================] - 0s 149us/step - loss: 0.6936 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 326/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6937 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 327/1000\n",
      "420/420 [==============================] - 0s 144us/step - loss: 0.6928 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 328/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 329/1000\n",
      "420/420 [==============================] - 0s 170us/step - loss: 0.6932 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 330/1000\n",
      "420/420 [==============================] - 0s 197us/step - loss: 0.6945 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 331/1000\n",
      "420/420 [==============================] - 0s 148us/step - loss: 0.6933 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 332/1000\n",
      "420/420 [==============================] - 0s 172us/step - loss: 0.6939 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 333/1000\n",
      "420/420 [==============================] - 0s 185us/step - loss: 0.6933 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 334/1000\n",
      "420/420 [==============================] - 0s 275us/step - loss: 0.6940 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 335/1000\n",
      "420/420 [==============================] - 0s 191us/step - loss: 0.6934 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 336/1000\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.6934 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 170us/step - loss: 0.6938 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 338/1000\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.6939 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 339/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6939 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 340/1000\n",
      "420/420 [==============================] - 0s 205us/step - loss: 0.6933 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 341/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6934 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 342/1000\n",
      "420/420 [==============================] - 0s 206us/step - loss: 0.6926 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 343/1000\n",
      "420/420 [==============================] - 0s 236us/step - loss: 0.6937 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 344/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6927 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 345/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6935 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 346/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6932 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 347/1000\n",
      "420/420 [==============================] - 0s 252us/step - loss: 0.6918 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 348/1000\n",
      "420/420 [==============================] - 0s 275us/step - loss: 0.6937 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 349/1000\n",
      "420/420 [==============================] - 0s 295us/step - loss: 0.6936 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 350/1000\n",
      "420/420 [==============================] - 0s 165us/step - loss: 0.6929 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 351/1000\n",
      "420/420 [==============================] - 0s 265us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 352/1000\n",
      "420/420 [==============================] - 0s 305us/step - loss: 0.6935 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 353/1000\n",
      "420/420 [==============================] - 0s 288us/step - loss: 0.6934 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 354/1000\n",
      "420/420 [==============================] - 0s 229us/step - loss: 0.6938 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 355/1000\n",
      "420/420 [==============================] - 0s 259us/step - loss: 0.6931 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 356/1000\n",
      "420/420 [==============================] - 0s 283us/step - loss: 0.6937 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 357/1000\n",
      "420/420 [==============================] - 0s 265us/step - loss: 0.6937 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 358/1000\n",
      "420/420 [==============================] - 0s 300us/step - loss: 0.6931 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 359/1000\n",
      "420/420 [==============================] - 0s 299us/step - loss: 0.6929 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 360/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6923 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 361/1000\n",
      "420/420 [==============================] - 0s 192us/step - loss: 0.6923 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 362/1000\n",
      "420/420 [==============================] - 0s 262us/step - loss: 0.6928 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 363/1000\n",
      "420/420 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 364/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6936 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 365/1000\n",
      "420/420 [==============================] - 0s 298us/step - loss: 0.6936 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 366/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6937 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 367/1000\n",
      "420/420 [==============================] - 0s 325us/step - loss: 0.6940 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 368/1000\n",
      "420/420 [==============================] - 0s 278us/step - loss: 0.6939 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 369/1000\n",
      "420/420 [==============================] - 0s 296us/step - loss: 0.6937 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 370/1000\n",
      "420/420 [==============================] - 0s 314us/step - loss: 0.6935 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 371/1000\n",
      "420/420 [==============================] - 0s 184us/step - loss: 0.6930 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 372/1000\n",
      "420/420 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 373/1000\n",
      "420/420 [==============================] - 0s 153us/step - loss: 0.6932 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 374/1000\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.6935 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 375/1000\n",
      "420/420 [==============================] - 0s 153us/step - loss: 0.6934 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 376/1000\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.6943 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 377/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6928 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 378/1000\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.6931 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 120us/step - loss: 0.6936 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 380/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6929 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 381/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6925 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 382/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6938 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 383/1000\n",
      "420/420 [==============================] - 0s 238us/step - loss: 0.6936 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 384/1000\n",
      "420/420 [==============================] - 0s 260us/step - loss: 0.6927 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 385/1000\n",
      "420/420 [==============================] - 0s 242us/step - loss: 0.6940 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 386/1000\n",
      "420/420 [==============================] - 0s 248us/step - loss: 0.6933 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 387/1000\n",
      "420/420 [==============================] - 0s 301us/step - loss: 0.6937 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 388/1000\n",
      "420/420 [==============================] - 0s 278us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 389/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6931 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 390/1000\n",
      "420/420 [==============================] - 0s 158us/step - loss: 0.6936 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 391/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6936 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 392/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6930 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 393/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6934 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 394/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6930 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 395/1000\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.6929 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 396/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6935 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 397/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6929 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 398/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6934 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 399/1000\n",
      "420/420 [==============================] - 0s 146us/step - loss: 0.6934 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 400/1000\n",
      "420/420 [==============================] - 0s 144us/step - loss: 0.6939 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 401/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6936 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 402/1000\n",
      "420/420 [==============================] - 0s 144us/step - loss: 0.6938 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 403/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6927 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 404/1000\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.6931 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 405/1000\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.6933 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 406/1000\n",
      "420/420 [==============================] - 0s 170us/step - loss: 0.6923 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 407/1000\n",
      "420/420 [==============================] - 0s 165us/step - loss: 0.6933 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 408/1000\n",
      "420/420 [==============================] - 0s 247us/step - loss: 0.6927 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 409/1000\n",
      "420/420 [==============================] - 0s 286us/step - loss: 0.6936 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 410/1000\n",
      "420/420 [==============================] - 0s 275us/step - loss: 0.6931 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 411/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6929 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 412/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 413/1000\n",
      "420/420 [==============================] - 0s 321us/step - loss: 0.6935 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 414/1000\n",
      "420/420 [==============================] - 0s 321us/step - loss: 0.6934 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 415/1000\n",
      "420/420 [==============================] - 0s 332us/step - loss: 0.6938 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 416/1000\n",
      "420/420 [==============================] - 0s 347us/step - loss: 0.6932 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 417/1000\n",
      "420/420 [==============================] - 0s 247us/step - loss: 0.6935 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 418/1000\n",
      "420/420 [==============================] - 0s 287us/step - loss: 0.6938 - acc: 0.4476 - binary_accuracy: 0.4476 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 419/1000\n",
      "420/420 [==============================] - 0s 210us/step - loss: 0.6931 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 420/1000\n",
      "420/420 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 259us/step - loss: 0.6924 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 422/1000\n",
      "420/420 [==============================] - 0s 298us/step - loss: 0.6937 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 423/1000\n",
      "420/420 [==============================] - 0s 314us/step - loss: 0.6929 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 424/1000\n",
      "420/420 [==============================] - 0s 240us/step - loss: 0.6935 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 425/1000\n",
      "420/420 [==============================] - 0s 248us/step - loss: 0.6931 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 426/1000\n",
      "420/420 [==============================] - 0s 235us/step - loss: 0.6930 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 427/1000\n",
      "420/420 [==============================] - 0s 175us/step - loss: 0.6936 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 428/1000\n",
      "420/420 [==============================] - 0s 332us/step - loss: 0.6926 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 429/1000\n",
      "420/420 [==============================] - 0s 202us/step - loss: 0.6922 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 430/1000\n",
      "420/420 [==============================] - 0s 243us/step - loss: 0.6936 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 431/1000\n",
      "420/420 [==============================] - 0s 230us/step - loss: 0.6931 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 432/1000\n",
      "420/420 [==============================] - 0s 205us/step - loss: 0.6939 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 433/1000\n",
      "420/420 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 434/1000\n",
      "420/420 [==============================] - 0s 243us/step - loss: 0.6930 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 435/1000\n",
      "420/420 [==============================] - 0s 178us/step - loss: 0.6932 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 436/1000\n",
      "420/420 [==============================] - 0s 217us/step - loss: 0.6930 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 437/1000\n",
      "420/420 [==============================] - 0s 194us/step - loss: 0.6925 - acc: 0.5381 - binary_accuracy: 0.5381 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 438/1000\n",
      "420/420 [==============================] - 0s 182us/step - loss: 0.6937 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 439/1000\n",
      "420/420 [==============================] - 0s 290us/step - loss: 0.6933 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 440/1000\n",
      "420/420 [==============================] - 0s 202us/step - loss: 0.6933 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 441/1000\n",
      "420/420 [==============================] - 0s 226us/step - loss: 0.6939 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 442/1000\n",
      "420/420 [==============================] - 0s 199us/step - loss: 0.6934 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 443/1000\n",
      "420/420 [==============================] - 0s 192us/step - loss: 0.6937 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 444/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6934 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 445/1000\n",
      "420/420 [==============================] - 0s 184us/step - loss: 0.6935 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 446/1000\n",
      "420/420 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 447/1000\n",
      "420/420 [==============================] - 0s 201us/step - loss: 0.6931 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 448/1000\n",
      "420/420 [==============================] - 0s 168us/step - loss: 0.6931 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 449/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6931 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 450/1000\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.6929 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 451/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6932 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 452/1000\n",
      "420/420 [==============================] - 0s 293us/step - loss: 0.6932 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 453/1000\n",
      "420/420 [==============================] - 0s 255us/step - loss: 0.6933 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 454/1000\n",
      "420/420 [==============================] - 0s 267us/step - loss: 0.6935 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 455/1000\n",
      "420/420 [==============================] - 0s 221us/step - loss: 0.6934 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 456/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6933 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 457/1000\n",
      "420/420 [==============================] - 0s 250us/step - loss: 0.6937 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 458/1000\n",
      "420/420 [==============================] - 0s 257us/step - loss: 0.6929 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 459/1000\n",
      "420/420 [==============================] - 0s 318us/step - loss: 0.6931 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 460/1000\n",
      "420/420 [==============================] - 0s 324us/step - loss: 0.6929 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 461/1000\n",
      "420/420 [==============================] - 0s 295us/step - loss: 0.6934 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 462/1000\n",
      "420/420 [==============================] - 0s 201us/step - loss: 0.6936 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 463/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 211us/step - loss: 0.6926 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 464/1000\n",
      "420/420 [==============================] - 0s 214us/step - loss: 0.6942 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 465/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6923 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 466/1000\n",
      "420/420 [==============================] - 0s 199us/step - loss: 0.6941 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 467/1000\n",
      "420/420 [==============================] - 0s 271us/step - loss: 0.6917 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 468/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6936 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 469/1000\n",
      "420/420 [==============================] - 0s 202us/step - loss: 0.6929 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 470/1000\n",
      "420/420 [==============================] - 0s 183us/step - loss: 0.6934 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 471/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6930 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 472/1000\n",
      "420/420 [==============================] - 0s 205us/step - loss: 0.6938 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 473/1000\n",
      "420/420 [==============================] - 0s 244us/step - loss: 0.6925 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 474/1000\n",
      "420/420 [==============================] - 0s 271us/step - loss: 0.6939 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 475/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6942 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6947 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 476/1000\n",
      "420/420 [==============================] - 0s 262us/step - loss: 0.6936 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6949 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 477/1000\n",
      "420/420 [==============================] - 0s 278us/step - loss: 0.6936 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6948 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 478/1000\n",
      "420/420 [==============================] - 0s 243us/step - loss: 0.6933 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 479/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6941 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 480/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6933 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 481/1000\n",
      "420/420 [==============================] - 0s 319us/step - loss: 0.6928 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 482/1000\n",
      "420/420 [==============================] - 0s 339us/step - loss: 0.6935 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 483/1000\n",
      "420/420 [==============================] - 0s 302us/step - loss: 0.6941 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 484/1000\n",
      "420/420 [==============================] - 0s 235us/step - loss: 0.6935 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 485/1000\n",
      "420/420 [==============================] - 0s 115us/step - loss: 0.6941 - acc: 0.4429 - binary_accuracy: 0.4429 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 486/1000\n",
      "420/420 [==============================] - 0s 120us/step - loss: 0.6937 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 487/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6934 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 488/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6928 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 489/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6935 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 490/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6939 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 491/1000\n",
      "420/420 [==============================] - 0s 115us/step - loss: 0.6935 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 492/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6929 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 493/1000\n",
      "420/420 [==============================] - 0s 118us/step - loss: 0.6935 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 494/1000\n",
      "420/420 [==============================] - 0s 125us/step - loss: 0.6936 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 495/1000\n",
      "420/420 [==============================] - 0s 114us/step - loss: 0.6933 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 496/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6943 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 497/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6938 - acc: 0.4500 - binary_accuracy: 0.4500 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 498/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6934 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 499/1000\n",
      "420/420 [==============================] - 0s 170us/step - loss: 0.6941 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 500/1000\n",
      "420/420 [==============================] - 0s 201us/step - loss: 0.6939 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 501/1000\n",
      "420/420 [==============================] - 0s 227us/step - loss: 0.6939 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 502/1000\n",
      "420/420 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 503/1000\n",
      "420/420 [==============================] - 0s 263us/step - loss: 0.6936 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 504/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6935 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 165us/step - loss: 0.6931 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 506/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6935 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 507/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6928 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 508/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6930 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6917 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 509/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6925 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 510/1000\n",
      "420/420 [==============================] - 0s 226us/step - loss: 0.6916 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 511/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6926 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 512/1000\n",
      "420/420 [==============================] - 0s 125us/step - loss: 0.6930 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 513/1000\n",
      "420/420 [==============================] - 0s 134us/step - loss: 0.6934 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 514/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6933 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 515/1000\n",
      "420/420 [==============================] - 0s 238us/step - loss: 0.6922 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 516/1000\n",
      "420/420 [==============================] - 0s 249us/step - loss: 0.6945 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 517/1000\n",
      "420/420 [==============================] - 0s 233us/step - loss: 0.6927 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 518/1000\n",
      "420/420 [==============================] - 0s 285us/step - loss: 0.6936 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 519/1000\n",
      "420/420 [==============================] - 0s 314us/step - loss: 0.6928 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 520/1000\n",
      "420/420 [==============================] - 0s 345us/step - loss: 0.6935 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 521/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6937 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 522/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6928 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 523/1000\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.6931 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 524/1000\n",
      "420/420 [==============================] - 0s 141us/step - loss: 0.6933 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 525/1000\n",
      "420/420 [==============================] - 0s 288us/step - loss: 0.6925 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 526/1000\n",
      "420/420 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 527/1000\n",
      "420/420 [==============================] - 0s 190us/step - loss: 0.6939 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 528/1000\n",
      "420/420 [==============================] - 0s 163us/step - loss: 0.6938 - acc: 0.4333 - binary_accuracy: 0.4333 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 529/1000\n",
      "420/420 [==============================] - 0s 171us/step - loss: 0.6936 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 530/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6920 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 531/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6937 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 532/1000\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.6927 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6942 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 533/1000\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.6929 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 534/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6934 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 535/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6927 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6946 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 536/1000\n",
      "420/420 [==============================] - 0s 216us/step - loss: 0.6945 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 537/1000\n",
      "420/420 [==============================] - 0s 221us/step - loss: 0.6934 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6947 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 538/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6923 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6949 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 539/1000\n",
      "420/420 [==============================] - 0s 273us/step - loss: 0.6931 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6950 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 540/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6930 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6946 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 541/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6927 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 542/1000\n",
      "420/420 [==============================] - 0s 206us/step - loss: 0.6930 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6947 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 543/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6943 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6949 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 544/1000\n",
      "420/420 [==============================] - 0s 148us/step - loss: 0.6926 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6947 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 545/1000\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.6928 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 546/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6931 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 138us/step - loss: 0.6938 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 548/1000\n",
      "420/420 [==============================] - 0s 115us/step - loss: 0.6929 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 549/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6926 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6948 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 550/1000\n",
      "420/420 [==============================] - 0s 134us/step - loss: 0.6931 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6949 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 551/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6931 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6951 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 552/1000\n",
      "420/420 [==============================] - 0s 125us/step - loss: 0.6931 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6950 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 553/1000\n",
      "420/420 [==============================] - 0s 116us/step - loss: 0.6932 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6951 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 554/1000\n",
      "420/420 [==============================] - 0s 120us/step - loss: 0.6935 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6950 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 555/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6933 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6952 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 556/1000\n",
      "420/420 [==============================] - 0s 158us/step - loss: 0.6929 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6948 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 557/1000\n",
      "420/420 [==============================] - 0s 175us/step - loss: 0.6926 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6947 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 558/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6930 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6949 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 559/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6931 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6951 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 560/1000\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.6932 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6950 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 561/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6931 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6946 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 562/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6924 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 563/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6930 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 564/1000\n",
      "420/420 [==============================] - 0s 197us/step - loss: 0.6930 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 565/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6948 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 566/1000\n",
      "420/420 [==============================] - 0s 201us/step - loss: 0.6925 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 567/1000\n",
      "420/420 [==============================] - 0s 227us/step - loss: 0.6938 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 568/1000\n",
      "420/420 [==============================] - 0s 263us/step - loss: 0.6926 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 569/1000\n",
      "420/420 [==============================] - 0s 287us/step - loss: 0.6939 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 570/1000\n",
      "420/420 [==============================] - 0s 336us/step - loss: 0.6927 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 571/1000\n",
      "420/420 [==============================] - 0s 224us/step - loss: 0.6943 - acc: 0.4500 - binary_accuracy: 0.4500 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 572/1000\n",
      "420/420 [==============================] - 0s 228us/step - loss: 0.6923 - acc: 0.5452 - binary_accuracy: 0.5452 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 573/1000\n",
      "420/420 [==============================] - 0s 222us/step - loss: 0.6926 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 574/1000\n",
      "420/420 [==============================] - 0s 204us/step - loss: 0.6930 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 575/1000\n",
      "420/420 [==============================] - 0s 184us/step - loss: 0.6921 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 576/1000\n",
      "420/420 [==============================] - 0s 212us/step - loss: 0.6935 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 577/1000\n",
      "420/420 [==============================] - 0s 219us/step - loss: 0.6930 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 578/1000\n",
      "420/420 [==============================] - 0s 252us/step - loss: 0.6941 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 579/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6918 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 580/1000\n",
      "420/420 [==============================] - 0s 266us/step - loss: 0.6924 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 581/1000\n",
      "420/420 [==============================] - 0s 175us/step - loss: 0.6932 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 582/1000\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.6935 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 583/1000\n",
      "420/420 [==============================] - 0s 191us/step - loss: 0.6937 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 584/1000\n",
      "420/420 [==============================] - 0s 189us/step - loss: 0.6936 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 585/1000\n",
      "420/420 [==============================] - 0s 141us/step - loss: 0.6930 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 586/1000\n",
      "420/420 [==============================] - 0s 151us/step - loss: 0.6931 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 587/1000\n",
      "420/420 [==============================] - 0s 189us/step - loss: 0.6942 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 588/1000\n",
      "420/420 [==============================] - 0s 137us/step - loss: 0.6931 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 589/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 170us/step - loss: 0.6922 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 590/1000\n",
      "420/420 [==============================] - 0s 185us/step - loss: 0.6930 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 591/1000\n",
      "420/420 [==============================] - 0s 272us/step - loss: 0.6937 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 592/1000\n",
      "420/420 [==============================] - 0s 168us/step - loss: 0.6927 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 593/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6931 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 594/1000\n",
      "420/420 [==============================] - 0s 120us/step - loss: 0.6936 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 595/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6936 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 596/1000\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.6927 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 597/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6932 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 598/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6934 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 599/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6936 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 600/1000\n",
      "420/420 [==============================] - 0s 125us/step - loss: 0.6929 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 601/1000\n",
      "420/420 [==============================] - 0s 115us/step - loss: 0.6926 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 602/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6937 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 603/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6937 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 604/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6931 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 605/1000\n",
      "420/420 [==============================] - 0s 132us/step - loss: 0.6926 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 606/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6919 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 607/1000\n",
      "420/420 [==============================] - 0s 111us/step - loss: 0.6922 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 608/1000\n",
      "420/420 [==============================] - 0s 109us/step - loss: 0.6927 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 609/1000\n",
      "420/420 [==============================] - 0s 132us/step - loss: 0.6923 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 610/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6927 - acc: 0.5524 - binary_accuracy: 0.5524 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 611/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6927 - acc: 0.5405 - binary_accuracy: 0.5405 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 612/1000\n",
      "420/420 [==============================] - 0s 186us/step - loss: 0.6925 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 613/1000\n",
      "420/420 [==============================] - 0s 142us/step - loss: 0.6930 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 614/1000\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.6926 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 615/1000\n",
      "420/420 [==============================] - 0s 170us/step - loss: 0.6926 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 616/1000\n",
      "420/420 [==============================] - 0s 114us/step - loss: 0.6928 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 617/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6931 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 618/1000\n",
      "420/420 [==============================] - 0s 114us/step - loss: 0.6928 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 619/1000\n",
      "420/420 [==============================] - 0s 105us/step - loss: 0.6927 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6931 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 620/1000\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.6924 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 621/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6942 - acc: 0.4429 - binary_accuracy: 0.4429 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 622/1000\n",
      "420/420 [==============================] - 0s 134us/step - loss: 0.6925 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 623/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6947 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 624/1000\n",
      "420/420 [==============================] - 0s 114us/step - loss: 0.6933 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 625/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6932 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 626/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6930 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 627/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6940 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 628/1000\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.6938 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 629/1000\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.6936 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 630/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6929 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 137us/step - loss: 0.6935 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 632/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6936 - acc: 0.4238 - binary_accuracy: 0.4238 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 633/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6928 - acc: 0.5405 - binary_accuracy: 0.5405 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 634/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6932 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 635/1000\n",
      "420/420 [==============================] - 0s 118us/step - loss: 0.6928 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 636/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6942 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 637/1000\n",
      "420/420 [==============================] - 0s 132us/step - loss: 0.6928 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 638/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6935 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 639/1000\n",
      "420/420 [==============================] - 0s 189us/step - loss: 0.6942 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 640/1000\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.6928 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 641/1000\n",
      "420/420 [==============================] - 0s 113us/step - loss: 0.6936 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 642/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6936 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 643/1000\n",
      "420/420 [==============================] - 0s 120us/step - loss: 0.6938 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 644/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6943 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 645/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6933 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 646/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6925 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 647/1000\n",
      "420/420 [==============================] - 0s 163us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 648/1000\n",
      "420/420 [==============================] - 0s 170us/step - loss: 0.6930 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 649/1000\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.6931 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 650/1000\n",
      "420/420 [==============================] - 0s 243us/step - loss: 0.6935 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 651/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6932 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 652/1000\n",
      "420/420 [==============================] - 0s 173us/step - loss: 0.6925 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 653/1000\n",
      "420/420 [==============================] - 0s 199us/step - loss: 0.6936 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 654/1000\n",
      "420/420 [==============================] - 0s 165us/step - loss: 0.6927 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 655/1000\n",
      "420/420 [==============================] - 0s 217us/step - loss: 0.6941 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 656/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6937 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 657/1000\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.6935 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 658/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6930 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 659/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6935 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 660/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6938 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 661/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6933 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 662/1000\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.6931 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 663/1000\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.6943 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 664/1000\n",
      "420/420 [==============================] - 0s 140us/step - loss: 0.6937 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 665/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6945 - acc: 0.4798 - binary_accuracy: 0.4798 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 666/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6936 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 667/1000\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.6931 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 668/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6927 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 669/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6933 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 670/1000\n",
      "420/420 [==============================] - 0s 137us/step - loss: 0.6928 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 671/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6935 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 672/1000\n",
      "420/420 [==============================] - 0s 132us/step - loss: 0.6936 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 674/1000\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.6930 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 675/1000\n",
      "420/420 [==============================] - 0s 166us/step - loss: 0.6928 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 676/1000\n",
      "420/420 [==============================] - 0s 142us/step - loss: 0.6941 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 677/1000\n",
      "420/420 [==============================] - 0s 286us/step - loss: 0.6944 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 678/1000\n",
      "420/420 [==============================] - 0s 286us/step - loss: 0.6940 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 679/1000\n",
      "420/420 [==============================] - 0s 290us/step - loss: 0.6930 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 680/1000\n",
      "420/420 [==============================] - 0s 277us/step - loss: 0.6937 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 681/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6937 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 682/1000\n",
      "420/420 [==============================] - 0s 262us/step - loss: 0.6929 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 683/1000\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.6932 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 684/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6921 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 685/1000\n",
      "420/420 [==============================] - 0s 243us/step - loss: 0.6935 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 686/1000\n",
      "420/420 [==============================] - 0s 284us/step - loss: 0.6933 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 687/1000\n",
      "420/420 [==============================] - 0s 261us/step - loss: 0.6936 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 688/1000\n",
      "420/420 [==============================] - 0s 293us/step - loss: 0.6927 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 689/1000\n",
      "420/420 [==============================] - 0s 273us/step - loss: 0.6925 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 690/1000\n",
      "420/420 [==============================] - 0s 326us/step - loss: 0.6940 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 691/1000\n",
      "420/420 [==============================] - 0s 275us/step - loss: 0.6939 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 692/1000\n",
      "420/420 [==============================] - 0s 244us/step - loss: 0.6941 - acc: 0.4476 - binary_accuracy: 0.4476 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 693/1000\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.6913 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 694/1000\n",
      "420/420 [==============================] - 0s 199us/step - loss: 0.6938 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 695/1000\n",
      "420/420 [==============================] - 0s 319us/step - loss: 0.6939 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 696/1000\n",
      "420/420 [==============================] - 0s 315us/step - loss: 0.6925 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 697/1000\n",
      "420/420 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 698/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6939 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 699/1000\n",
      "420/420 [==============================] - 0s 211us/step - loss: 0.6936 - acc: 0.4667 - binary_accuracy: 0.4667 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 700/1000\n",
      "420/420 [==============================] - 0s 289us/step - loss: 0.6937 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 701/1000\n",
      "420/420 [==============================] - 0s 283us/step - loss: 0.6925 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 702/1000\n",
      "420/420 [==============================] - 0s 208us/step - loss: 0.6932 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 703/1000\n",
      "420/420 [==============================] - 0s 255us/step - loss: 0.6925 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 704/1000\n",
      "420/420 [==============================] - 0s 257us/step - loss: 0.6933 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 705/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6933 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 706/1000\n",
      "420/420 [==============================] - 0s 265us/step - loss: 0.6923 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 707/1000\n",
      "420/420 [==============================] - 0s 301us/step - loss: 0.6937 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 708/1000\n",
      "420/420 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 709/1000\n",
      "420/420 [==============================] - 0s 226us/step - loss: 0.6928 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 710/1000\n",
      "420/420 [==============================] - 0s 236us/step - loss: 0.6936 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 711/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6926 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 712/1000\n",
      "420/420 [==============================] - 0s 306us/step - loss: 0.6940 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 713/1000\n",
      "420/420 [==============================] - 0s 273us/step - loss: 0.6938 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 714/1000\n",
      "420/420 [==============================] - 0s 330us/step - loss: 0.6941 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 336us/step - loss: 0.6923 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 716/1000\n",
      "420/420 [==============================] - 0s 324us/step - loss: 0.6925 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 717/1000\n",
      "420/420 [==============================] - 0s 237us/step - loss: 0.6928 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 718/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6945 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 719/1000\n",
      "420/420 [==============================] - 0s 168us/step - loss: 0.6947 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 720/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6931 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 721/1000\n",
      "420/420 [==============================] - 0s 251us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 722/1000\n",
      "420/420 [==============================] - 0s 289us/step - loss: 0.6929 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 723/1000\n",
      "420/420 [==============================] - 0s 312us/step - loss: 0.6923 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 724/1000\n",
      "420/420 [==============================] - 0s 319us/step - loss: 0.6930 - acc: 0.4500 - binary_accuracy: 0.4500 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 725/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6936 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 726/1000\n",
      "420/420 [==============================] - 0s 210us/step - loss: 0.6933 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 727/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6933 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 728/1000\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.6926 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 729/1000\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.6942 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 730/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6940 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 731/1000\n",
      "420/420 [==============================] - 0s 130us/step - loss: 0.6933 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 732/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6935 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 733/1000\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.6933 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 734/1000\n",
      "420/420 [==============================] - 0s 191us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 735/1000\n",
      "420/420 [==============================] - 0s 182us/step - loss: 0.6937 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 736/1000\n",
      "420/420 [==============================] - 0s 139us/step - loss: 0.6931 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 737/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 738/1000\n",
      "420/420 [==============================] - 0s 184us/step - loss: 0.6938 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 739/1000\n",
      "420/420 [==============================] - 0s 206us/step - loss: 0.6930 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 740/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6930 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 741/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6934 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 742/1000\n",
      "420/420 [==============================] - 0s 310us/step - loss: 0.6930 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 743/1000\n",
      "420/420 [==============================] - 0s 283us/step - loss: 0.6930 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6916 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 744/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6937 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6917 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 745/1000\n",
      "420/420 [==============================] - 0s 277us/step - loss: 0.6930 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 746/1000\n",
      "420/420 [==============================] - 0s 302us/step - loss: 0.6943 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 747/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6946 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 748/1000\n",
      "420/420 [==============================] - 0s 265us/step - loss: 0.6922 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6917 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 749/1000\n",
      "420/420 [==============================] - 0s 280us/step - loss: 0.6933 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6915 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 750/1000\n",
      "420/420 [==============================] - 0s 317us/step - loss: 0.6937 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 751/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6928 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 752/1000\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.6932 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 753/1000\n",
      "420/420 [==============================] - 0s 168us/step - loss: 0.6938 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 754/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6928 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 755/1000\n",
      "420/420 [==============================] - 0s 171us/step - loss: 0.6943 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 756/1000\n",
      "420/420 [==============================] - 0s 231us/step - loss: 0.6939 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 200us/step - loss: 0.6933 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 758/1000\n",
      "420/420 [==============================] - 0s 212us/step - loss: 0.6933 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 759/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6943 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 760/1000\n",
      "420/420 [==============================] - 0s 285us/step - loss: 0.6929 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 761/1000\n",
      "420/420 [==============================] - 0s 296us/step - loss: 0.6939 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 762/1000\n",
      "420/420 [==============================] - 0s 338us/step - loss: 0.6928 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 763/1000\n",
      "420/420 [==============================] - 0s 313us/step - loss: 0.6934 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 764/1000\n",
      "420/420 [==============================] - 0s 239us/step - loss: 0.6929 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 765/1000\n",
      "420/420 [==============================] - 0s 310us/step - loss: 0.6933 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 766/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6932 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 767/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6935 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 768/1000\n",
      "420/420 [==============================] - 0s 283us/step - loss: 0.6927 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 769/1000\n",
      "420/420 [==============================] - 0s 298us/step - loss: 0.6933 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 770/1000\n",
      "420/420 [==============================] - 0s 268us/step - loss: 0.6938 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 771/1000\n",
      "420/420 [==============================] - 0s 277us/step - loss: 0.6929 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 772/1000\n",
      "420/420 [==============================] - 0s 292us/step - loss: 0.6928 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 773/1000\n",
      "420/420 [==============================] - 0s 269us/step - loss: 0.6931 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 774/1000\n",
      "420/420 [==============================] - 0s 262us/step - loss: 0.6928 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 775/1000\n",
      "420/420 [==============================] - 0s 321us/step - loss: 0.6931 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 776/1000\n",
      "420/420 [==============================] - 0s 289us/step - loss: 0.6930 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 777/1000\n",
      "420/420 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 778/1000\n",
      "420/420 [==============================] - 0s 245us/step - loss: 0.6929 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 779/1000\n",
      "420/420 [==============================] - 0s 201us/step - loss: 0.6922 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 780/1000\n",
      "420/420 [==============================] - 0s 277us/step - loss: 0.6927 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 781/1000\n",
      "420/420 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 782/1000\n",
      "420/420 [==============================] - 0s 255us/step - loss: 0.6935 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 783/1000\n",
      "420/420 [==============================] - 0s 245us/step - loss: 0.6945 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 784/1000\n",
      "420/420 [==============================] - 0s 284us/step - loss: 0.6934 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 785/1000\n",
      "420/420 [==============================] - 0s 260us/step - loss: 0.6935 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 786/1000\n",
      "420/420 [==============================] - 0s 253us/step - loss: 0.6933 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 787/1000\n",
      "420/420 [==============================] - 0s 239us/step - loss: 0.6921 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 788/1000\n",
      "420/420 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6942 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 789/1000\n",
      "420/420 [==============================] - 0s 200us/step - loss: 0.6919 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6945 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 790/1000\n",
      "420/420 [==============================] - 0s 191us/step - loss: 0.6935 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6944 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 791/1000\n",
      "420/420 [==============================] - 0s 209us/step - loss: 0.6933 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 792/1000\n",
      "420/420 [==============================] - 0s 215us/step - loss: 0.6934 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 793/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6934 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 794/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6939 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 795/1000\n",
      "420/420 [==============================] - 0s 252us/step - loss: 0.6944 - acc: 0.4571 - binary_accuracy: 0.4571 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 796/1000\n",
      "420/420 [==============================] - 0s 217us/step - loss: 0.6925 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 797/1000\n",
      "420/420 [==============================] - 0s 260us/step - loss: 0.6930 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 798/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6935 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 799/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 308us/step - loss: 0.6929 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 800/1000\n",
      "420/420 [==============================] - 0s 300us/step - loss: 0.6931 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 801/1000\n",
      "420/420 [==============================] - 0s 218us/step - loss: 0.6926 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 802/1000\n",
      "420/420 [==============================] - 0s 216us/step - loss: 0.6923 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 803/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6926 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 804/1000\n",
      "420/420 [==============================] - 0s 213us/step - loss: 0.6943 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 805/1000\n",
      "420/420 [==============================] - 0s 275us/step - loss: 0.6930 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 806/1000\n",
      "420/420 [==============================] - 0s 302us/step - loss: 0.6931 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 807/1000\n",
      "420/420 [==============================] - 0s 221us/step - loss: 0.6928 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 808/1000\n",
      "420/420 [==============================] - 0s 276us/step - loss: 0.6931 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 809/1000\n",
      "420/420 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 810/1000\n",
      "420/420 [==============================] - 0s 286us/step - loss: 0.6933 - acc: 0.5452 - binary_accuracy: 0.5452 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 811/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6930 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 812/1000\n",
      "420/420 [==============================] - 0s 248us/step - loss: 0.6924 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 813/1000\n",
      "420/420 [==============================] - 0s 263us/step - loss: 0.6943 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 814/1000\n",
      "420/420 [==============================] - 0s 233us/step - loss: 0.6943 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 815/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6932 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 816/1000\n",
      "420/420 [==============================] - 0s 244us/step - loss: 0.6930 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 817/1000\n",
      "420/420 [==============================] - 0s 200us/step - loss: 0.6940 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 818/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6919 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 819/1000\n",
      "420/420 [==============================] - 0s 276us/step - loss: 0.6938 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 820/1000\n",
      "420/420 [==============================] - 0s 219us/step - loss: 0.6940 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 821/1000\n",
      "420/420 [==============================] - 0s 217us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 822/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6936 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 823/1000\n",
      "420/420 [==============================] - 0s 282us/step - loss: 0.6927 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 824/1000\n",
      "420/420 [==============================] - 0s 293us/step - loss: 0.6937 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 825/1000\n",
      "420/420 [==============================] - 0s 295us/step - loss: 0.6919 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 826/1000\n",
      "420/420 [==============================] - 0s 242us/step - loss: 0.6934 - acc: 0.4381 - binary_accuracy: 0.4381 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 827/1000\n",
      "420/420 [==============================] - 0s 200us/step - loss: 0.6927 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 828/1000\n",
      "420/420 [==============================] - 0s 217us/step - loss: 0.6934 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 829/1000\n",
      "420/420 [==============================] - 0s 235us/step - loss: 0.6936 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 830/1000\n",
      "420/420 [==============================] - 0s 226us/step - loss: 0.6923 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 831/1000\n",
      "420/420 [==============================] - 0s 200us/step - loss: 0.6945 - acc: 0.4571 - binary_accuracy: 0.4571 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 832/1000\n",
      "420/420 [==============================] - 0s 187us/step - loss: 0.6929 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 833/1000\n",
      "420/420 [==============================] - 0s 269us/step - loss: 0.6937 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 834/1000\n",
      "420/420 [==============================] - 0s 334us/step - loss: 0.6949 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 835/1000\n",
      "420/420 [==============================] - 0s 301us/step - loss: 0.6934 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 836/1000\n",
      "420/420 [==============================] - 0s 303us/step - loss: 0.6926 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 837/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6938 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 838/1000\n",
      "420/420 [==============================] - 0s 225us/step - loss: 0.6941 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 839/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6936 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 840/1000\n",
      "420/420 [==============================] - 0s 235us/step - loss: 0.6939 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 280us/step - loss: 0.6922 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 842/1000\n",
      "420/420 [==============================] - 0s 294us/step - loss: 0.6927 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6935 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 843/1000\n",
      "420/420 [==============================] - 0s 321us/step - loss: 0.6932 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 844/1000\n",
      "420/420 [==============================] - 0s 220us/step - loss: 0.6939 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6931 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 845/1000\n",
      "420/420 [==============================] - 0s 306us/step - loss: 0.6924 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 846/1000\n",
      "420/420 [==============================] - 0s 322us/step - loss: 0.6939 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 847/1000\n",
      "420/420 [==============================] - 0s 315us/step - loss: 0.6928 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 848/1000\n",
      "420/420 [==============================] - 0s 327us/step - loss: 0.6941 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 849/1000\n",
      "420/420 [==============================] - 0s 338us/step - loss: 0.6926 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 850/1000\n",
      "420/420 [==============================] - 0s 273us/step - loss: 0.6936 - acc: 0.4643 - binary_accuracy: 0.4643 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 851/1000\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.6939 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 852/1000\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.6930 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 853/1000\n",
      "420/420 [==============================] - 0s 191us/step - loss: 0.6927 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 854/1000\n",
      "420/420 [==============================] - 0s 289us/step - loss: 0.6929 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 855/1000\n",
      "420/420 [==============================] - 0s 277us/step - loss: 0.6937 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 856/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6934 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 857/1000\n",
      "420/420 [==============================] - 0s 227us/step - loss: 0.6923 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 858/1000\n",
      "420/420 [==============================] - 0s 299us/step - loss: 0.6938 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 859/1000\n",
      "420/420 [==============================] - 0s 236us/step - loss: 0.6940 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 860/1000\n",
      "420/420 [==============================] - 0s 271us/step - loss: 0.6924 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 861/1000\n",
      "420/420 [==============================] - 0s 269us/step - loss: 0.6936 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 862/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6932 - acc: 0.5262 - binary_accuracy: 0.5262 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 863/1000\n",
      "420/420 [==============================] - 0s 297us/step - loss: 0.6932 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 864/1000\n",
      "420/420 [==============================] - 0s 307us/step - loss: 0.6929 - acc: 0.4452 - binary_accuracy: 0.4452 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 865/1000\n",
      "420/420 [==============================] - 0s 307us/step - loss: 0.6937 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 866/1000\n",
      "420/420 [==============================] - 0s 260us/step - loss: 0.6928 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 867/1000\n",
      "420/420 [==============================] - 0s 267us/step - loss: 0.6938 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 868/1000\n",
      "420/420 [==============================] - 0s 229us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 869/1000\n",
      "420/420 [==============================] - 0s 156us/step - loss: 0.6918 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6943 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 870/1000\n",
      "420/420 [==============================] - 0s 194us/step - loss: 0.6929 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 871/1000\n",
      "420/420 [==============================] - 0s 165us/step - loss: 0.6927 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6941 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 872/1000\n",
      "420/420 [==============================] - 0s 141us/step - loss: 0.6927 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 873/1000\n",
      "420/420 [==============================] - 0s 269us/step - loss: 0.6936 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6939 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 874/1000\n",
      "420/420 [==============================] - 0s 271us/step - loss: 0.6923 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 875/1000\n",
      "420/420 [==============================] - 0s 276us/step - loss: 0.6925 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 876/1000\n",
      "420/420 [==============================] - 0s 251us/step - loss: 0.6935 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 877/1000\n",
      "420/420 [==============================] - 0s 245us/step - loss: 0.6941 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6940 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 878/1000\n",
      "420/420 [==============================] - 0s 204us/step - loss: 0.6938 - acc: 0.4690 - binary_accuracy: 0.4690 - val_loss: 0.6936 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 879/1000\n",
      "420/420 [==============================] - 0s 199us/step - loss: 0.6932 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 880/1000\n",
      "420/420 [==============================] - 0s 204us/step - loss: 0.6933 - acc: 0.5036 - binary_accuracy: 0.5036 - val_loss: 0.6938 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 881/1000\n",
      "420/420 [==============================] - 0s 206us/step - loss: 0.6938 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6937 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 882/1000\n",
      "420/420 [==============================] - 0s 206us/step - loss: 0.6938 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 213us/step - loss: 0.6937 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 884/1000\n",
      "420/420 [==============================] - 0s 249us/step - loss: 0.6924 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 885/1000\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.6923 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 886/1000\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.6938 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 887/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6931 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 888/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6936 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 889/1000\n",
      "420/420 [==============================] - 0s 118us/step - loss: 0.6929 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 890/1000\n",
      "420/420 [==============================] - 0s 116us/step - loss: 0.6922 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 891/1000\n",
      "420/420 [==============================] - 0s 112us/step - loss: 0.6934 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 892/1000\n",
      "420/420 [==============================] - 0s 153us/step - loss: 0.6925 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 893/1000\n",
      "420/420 [==============================] - 0s 154us/step - loss: 0.6922 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 894/1000\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.6935 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 895/1000\n",
      "420/420 [==============================] - 0s 192us/step - loss: 0.6920 - acc: 0.5476 - binary_accuracy: 0.5476 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 896/1000\n",
      "420/420 [==============================] - 0s 256us/step - loss: 0.6929 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 897/1000\n",
      "420/420 [==============================] - 0s 260us/step - loss: 0.6910 - acc: 0.5857 - binary_accuracy: 0.5857 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 898/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6931 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 899/1000\n",
      "420/420 [==============================] - 0s 310us/step - loss: 0.6938 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 900/1000\n",
      "420/420 [==============================] - 0s 321us/step - loss: 0.6934 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 901/1000\n",
      "420/420 [==============================] - 0s 334us/step - loss: 0.6927 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 902/1000\n",
      "420/420 [==============================] - 0s 234us/step - loss: 0.6922 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 903/1000\n",
      "420/420 [==============================] - 0s 315us/step - loss: 0.6929 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 904/1000\n",
      "420/420 [==============================] - 0s 327us/step - loss: 0.6936 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 905/1000\n",
      "420/420 [==============================] - 0s 341us/step - loss: 0.6932 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 906/1000\n",
      "420/420 [==============================] - 0s 285us/step - loss: 0.6936 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 907/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6917 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 908/1000\n",
      "420/420 [==============================] - 0s 279us/step - loss: 0.6939 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6915 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 909/1000\n",
      "420/420 [==============================] - 0s 297us/step - loss: 0.6931 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6916 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 910/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6935 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6917 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 911/1000\n",
      "420/420 [==============================] - 0s 286us/step - loss: 0.6935 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6915 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 912/1000\n",
      "420/420 [==============================] - 0s 228us/step - loss: 0.6925 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6913 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 913/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6933 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6916 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 914/1000\n",
      "420/420 [==============================] - 0s 161us/step - loss: 0.6936 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6917 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 915/1000\n",
      "420/420 [==============================] - 0s 149us/step - loss: 0.6927 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 916/1000\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.6913 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 917/1000\n",
      "420/420 [==============================] - 0s 221us/step - loss: 0.6922 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 918/1000\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.6937 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 919/1000\n",
      "420/420 [==============================] - 0s 202us/step - loss: 0.6931 - acc: 0.4881 - binary_accuracy: 0.4881 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 920/1000\n",
      "420/420 [==============================] - 0s 173us/step - loss: 0.6928 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 921/1000\n",
      "420/420 [==============================] - 0s 165us/step - loss: 0.6923 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 922/1000\n",
      "420/420 [==============================] - 0s 142us/step - loss: 0.6932 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 923/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6932 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 924/1000\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.6929 - acc: 0.5214 - binary_accuracy: 0.5214 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 160us/step - loss: 0.6932 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 926/1000\n",
      "420/420 [==============================] - 0s 265us/step - loss: 0.6932 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 927/1000\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.6938 - acc: 0.5048 - binary_accuracy: 0.5048 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 928/1000\n",
      "420/420 [==============================] - 0s 213us/step - loss: 0.6939 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 929/1000\n",
      "420/420 [==============================] - 0s 273us/step - loss: 0.6932 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 930/1000\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.6931 - acc: 0.4786 - binary_accuracy: 0.4786 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 931/1000\n",
      "420/420 [==============================] - 0s 114us/step - loss: 0.6933 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 932/1000\n",
      "420/420 [==============================] - 0s 127us/step - loss: 0.6928 - acc: 0.5357 - binary_accuracy: 0.5357 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 933/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6923 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6926 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 934/1000\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.6950 - acc: 0.4429 - binary_accuracy: 0.4429 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 935/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6940 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 936/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6920 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 937/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6926 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 938/1000\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.6933 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 939/1000\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.6935 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 940/1000\n",
      "420/420 [==============================] - 0s 123us/step - loss: 0.6928 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 941/1000\n",
      "420/420 [==============================] - 0s 158us/step - loss: 0.6940 - acc: 0.4976 - binary_accuracy: 0.4976 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 942/1000\n",
      "420/420 [==============================] - 0s 141us/step - loss: 0.6940 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 943/1000\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.6935 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 944/1000\n",
      "420/420 [==============================] - 0s 125us/step - loss: 0.6933 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 945/1000\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.6931 - acc: 0.5095 - binary_accuracy: 0.5095 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 946/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6929 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 947/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6933 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 948/1000\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6934 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 949/1000\n",
      "420/420 [==============================] - 0s 173us/step - loss: 0.6928 - acc: 0.5476 - binary_accuracy: 0.5476 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 950/1000\n",
      "420/420 [==============================] - 0s 153us/step - loss: 0.6927 - acc: 0.5476 - binary_accuracy: 0.5476 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 951/1000\n",
      "420/420 [==============================] - 0s 163us/step - loss: 0.6933 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 952/1000\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.6930 - acc: 0.4548 - binary_accuracy: 0.4548 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 953/1000\n",
      "420/420 [==============================] - 0s 271us/step - loss: 0.6923 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 954/1000\n",
      "420/420 [==============================] - 0s 293us/step - loss: 0.6934 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 955/1000\n",
      "420/420 [==============================] - 0s 238us/step - loss: 0.6939 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 956/1000\n",
      "420/420 [==============================] - 0s 212us/step - loss: 0.6932 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 957/1000\n",
      "420/420 [==============================] - 0s 268us/step - loss: 0.6926 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 958/1000\n",
      "420/420 [==============================] - 0s 281us/step - loss: 0.6937 - acc: 0.4500 - binary_accuracy: 0.4500 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 959/1000\n",
      "420/420 [==============================] - 0s 276us/step - loss: 0.6928 - acc: 0.5071 - binary_accuracy: 0.5071 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 960/1000\n",
      "420/420 [==============================] - 0s 270us/step - loss: 0.6935 - acc: 0.4810 - binary_accuracy: 0.4810 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 961/1000\n",
      "420/420 [==============================] - 0s 219us/step - loss: 0.6937 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 962/1000\n",
      "420/420 [==============================] - 0s 207us/step - loss: 0.6929 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 963/1000\n",
      "420/420 [==============================] - 0s 220us/step - loss: 0.6938 - acc: 0.4595 - binary_accuracy: 0.4595 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 964/1000\n",
      "420/420 [==============================] - 0s 220us/step - loss: 0.6937 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6934 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 965/1000\n",
      "420/420 [==============================] - 0s 284us/step - loss: 0.6932 - acc: 0.4762 - binary_accuracy: 0.4762 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 966/1000\n",
      "420/420 [==============================] - 0s 274us/step - loss: 0.6937 - acc: 0.5143 - binary_accuracy: 0.5143 - val_loss: 0.6933 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 0s 293us/step - loss: 0.6925 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6928 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 968/1000\n",
      "420/420 [==============================] - 0s 290us/step - loss: 0.6913 - acc: 0.5500 - binary_accuracy: 0.5500 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 969/1000\n",
      "420/420 [==============================] - 0s 319us/step - loss: 0.6941 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6930 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 970/1000\n",
      "420/420 [==============================] - 0s 228us/step - loss: 0.6922 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 971/1000\n",
      "420/420 [==============================] - 0s 301us/step - loss: 0.6930 - acc: 0.5286 - binary_accuracy: 0.5286 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 972/1000\n",
      "420/420 [==============================] - 0s 317us/step - loss: 0.6944 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6932 - val_acc: 0.4255 - val_binary_accuracy: 0.4255\n",
      "Epoch 973/1000\n",
      "420/420 [==============================] - 0s 239us/step - loss: 0.6933 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 974/1000\n",
      "420/420 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6931 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 975/1000\n",
      "420/420 [==============================] - 0s 272us/step - loss: 0.6920 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6927 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 976/1000\n",
      "420/420 [==============================] - 0s 251us/step - loss: 0.6926 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6929 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 977/1000\n",
      "420/420 [==============================] - 0s 238us/step - loss: 0.6939 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 978/1000\n",
      "420/420 [==============================] - 0s 312us/step - loss: 0.6934 - acc: 0.4857 - binary_accuracy: 0.4857 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 979/1000\n",
      "420/420 [==============================] - 0s 216us/step - loss: 0.6946 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 980/1000\n",
      "420/420 [==============================] - 0s 191us/step - loss: 0.6933 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 981/1000\n",
      "420/420 [==============================] - 0s 202us/step - loss: 0.6921 - acc: 0.5690 - binary_accuracy: 0.5690 - val_loss: 0.6925 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 982/1000\n",
      "420/420 [==============================] - 0s 262us/step - loss: 0.6932 - acc: 0.5310 - binary_accuracy: 0.5310 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 983/1000\n",
      "420/420 [==============================] - 0s 217us/step - loss: 0.6940 - acc: 0.4833 - binary_accuracy: 0.4833 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 984/1000\n",
      "420/420 [==============================] - 0s 258us/step - loss: 0.6938 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6917 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 985/1000\n",
      "420/420 [==============================] - 0s 215us/step - loss: 0.6932 - acc: 0.5238 - binary_accuracy: 0.5238 - val_loss: 0.6915 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 986/1000\n",
      "420/420 [==============================] - 0s 144us/step - loss: 0.6940 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6914 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 987/1000\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.6936 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6914 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 988/1000\n",
      "420/420 [==============================] - 0s 119us/step - loss: 0.6937 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6915 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 989/1000\n",
      "420/420 [==============================] - 0s 118us/step - loss: 0.6931 - acc: 0.5333 - binary_accuracy: 0.5333 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 990/1000\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.6935 - acc: 0.5190 - binary_accuracy: 0.5190 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 991/1000\n",
      "420/420 [==============================] - 0s 140us/step - loss: 0.6934 - acc: 0.4929 - binary_accuracy: 0.4929 - val_loss: 0.6918 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 992/1000\n",
      "420/420 [==============================] - 0s 161us/step - loss: 0.6941 - acc: 0.5000 - binary_accuracy: 0.5000 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 993/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6941 - acc: 0.4738 - binary_accuracy: 0.4738 - val_loss: 0.6921 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 994/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6918 - acc: 0.5167 - binary_accuracy: 0.5167 - val_loss: 0.6924 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 995/1000\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6939 - acc: 0.4619 - binary_accuracy: 0.4619 - val_loss: 0.6922 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 996/1000\n",
      "420/420 [==============================] - 0s 197us/step - loss: 0.6938 - acc: 0.4952 - binary_accuracy: 0.4952 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 997/1000\n",
      "420/420 [==============================] - 0s 183us/step - loss: 0.6944 - acc: 0.4714 - binary_accuracy: 0.4714 - val_loss: 0.6923 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 998/1000\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.6935 - acc: 0.5119 - binary_accuracy: 0.5119 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 999/1000\n",
      "420/420 [==============================] - 0s 196us/step - loss: 0.6936 - acc: 0.4905 - binary_accuracy: 0.4905 - val_loss: 0.6920 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "Epoch 1000/1000\n",
      "420/420 [==============================] - 0s 159us/step - loss: 0.6930 - acc: 0.5024 - binary_accuracy: 0.5024 - val_loss: 0.6919 - val_acc: 0.5745 - val_binary_accuracy: 0.5745\n",
      "--- 92.07048511505127 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "\n",
    "start_time = time.time()             # how long does it take?\n",
    "history = model.fit(X3,              # the (now oversampled) dataset\n",
    "          Y2,                        #true or false values for the dataset \n",
    "          epochs=1000,                 #number of iteration over data\n",
    "          batch_size=32,             #number of trainings between tests\n",
    "          verbose=1,                 #prints one line per epoch of progress bar\n",
    "          validation_split=0.1 )     #ratio of test to train\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsfXmcFcW1//fc2Rj2XVkdQFxRUBFxSdwNakQTE7eYBBOfUeOS/OJL1OfTxJjoS8yiMYlRozHuS6JixAVUjAsYQMGdRRYZ9m2AgRmGmXt+f3T37erqqu7qvt33DmN/Px+Y213bqaWr6ix1ipgZGTJkyJAhQxBy5SYgQ4YMGTK0f2SLRYYMGTJkCEW2WGTIkCFDhlBki0WGDBkyZAhFtlhkyJAhQ4ZQZItFhgwZMmQIRbZYZMgAgIj+RkQ3GcZdSkQnpE1ThgztCdlikSFDhgwZQpEtFhkydCAQUWW5acjQMZEtFhl2Gdjin/8moveIaBsR/ZWIdiOi54loKxFNI6JeQvyJRPQhETUQ0XQi2lcIO4iI3rHTPQagk1TWl4lorp32LSI60JDGU4noXSLaQkTLieinUvhRdn4Ndvgk+30tEf2GiJYR0WYiesN+dwwR1Sva4QT790+J6EkiepCItgCYRETjiGiGXcYqIrqDiKqF9PsT0VQi2khEa4joWiLanYi2E1EfId4hRLSOiKpM6p6hYyNbLDLsajgTwIkA9gJwGoDnAVwLoC+s8XwFABDRXgAeAfADAP0ATAHwLBFV2xPn0wAeANAbwBN2vrDTHgzgXgDfA9AHwF8ATCaiGgP6tgH4FoCeAE4FcAkRnWHnO9Sm9w82TWMAzLXT3QrgEABH2DT9GEDesE1OB/CkXeZDANoA/NBuk8MBHA/gUpuGbgCmAXgBwEAAewJ4mZlXA5gO4Cwh3/MBPMrMOw3pyNCBkS0WGXY1/IGZ1zDzCgCvA3ibmd9l5h0AngJwkB3vbADPMfNUe7K7FUAtrMl4PIAqAL9n5p3M/CSAWUIZ/wXgL8z8NjO3MfP9AHbY6QLBzNOZ+X1mzjPze7AWrKPt4G8AmMbMj9jlbmDmuUSUA/AdAFcy8wq7zLfsOplgBjM/bZfZxMxzmHkmM7cy81JYi51Dw5cBrGbm3zBzMzNvZea37bD7YS0QIKIKAOfCWlAzZMgWiwy7HNYIv5sUz13t3wMBLHMCmDkPYDmAQXbYCvZ60Vwm/N4DwI9sMU4DETUAGGKnCwQRHUZEr9rim80ALoa1w4edx6eKZH1hicFUYSZYLtGwFxH9i4hW26KpXxrQAADPANiPiIbD4t42M/N/YtKUoYMhWywydFSshDXpAwCIiGBNlCsArAIwyH7nYKjwezmAXzBzT+FfZ2Z+xKDchwFMBjCEmXsAuBOAU85yACMUadYDaNaEbQPQWahHBSwRlgjZdfSfAXwCYCQzd4clpgujAczcDOBxWBzQN5FxFRkEZItFho6KxwGcSkTH2wraH8ESJb0FYAaAVgBXEFElEX0VwDgh7d0ALra5BCKiLrbiuptBud0AbGTmZiIaB+A8IewhACcQ0Vl2uX2IaIzN9dwL4LdENJCIKojocFtHsgBAJ7v8KgDXAQjTnXQDsAVAIxHtA+ASIexfAHYnoh8QUQ0RdSOiw4TwvwOYBGAigAcN6pvhc4JsscjQIcHM82HJ3/8Aa+d+GoDTmLmFmVsAfBXWpLgJln7jn0La2bD0FnfY4YvsuCa4FMCNRLQVwPWwFi0n388AnAJr4doIS7k92g6+CsD7sHQnGwH8H4AcM2+287wHFle0DYDHOkqBq2AtUlthLXyPCTRshSViOg3AagALARwrhL8JS7H+jq3vyJABAEDZ5UcZMmQQQUSvAHiYme8pNy0Z2g+yxSJDhgwFENGhAKbC0rlsLTc9GdoPMjFUhgwZAABEdD+sMxg/yBaKDDIyziJDhgwZMoQi4ywyZMiQIUMoOozTsb59+3JdXV25yciQIUOGXQpz5sxZz8zy2R0fOsxiUVdXh9mzZ5ebjAwZMmTYpUBEy8JjZWKoDBkyZMhggGyxyJAhQ4YMocgWiwwZMmTIEIoOo7NQYefOnaivr0dzc3O5SUkdnTp1wuDBg1FVld1TkyFDhuTRoReL+vp6dOvWDXV1dfA6GO1YYGZs2LAB9fX1GDZsWLnJyZAhQwdEhxZDNTc3o0+fPh16oQAAIkKfPn0+FxxUhgwZyoMOvVgA6PALhYPPSz0zZMhQHnT4xSJDhgwZ0sbkeSuxualjX1WeLRYpo6GhAX/6058ipzvllFPQ0NCQAkUZMmRIEovWbsUVj7yLq56YV25SUkW2WKQM3WLR1tYWmG7KlCno2bNnWmRlyJAhITS15AEAqzY3lZmSdNGhraHaA66++mp8+umnGDNmDKqqqtC1a1cMGDAAc+fOxUcffYQzzjgDy5cvR3NzM6688kpcdNFFAFz3JY2NjTj55JNx1FFH4a233sKgQYPwzDPPoLa2tsw1y5Ahw+cJn5vF4mfPfoiPVm5JNM/9BnbHDaftHxjnlltuwQcffIC5c+di+vTpOPXUU/HBBx8UTFzvvfde9O7dG01NTTj00ENx5plnok+fPp48Fi5ciEceeQR33303zjrrLPzjH//A+eefn2hdMmTIkCEIqYqhiGgCEc0nokVEdLUifBIRrSOiufa/C4WwXxHRh0T0MRHdTh3E3GfcuHGesxC33347Ro8ejfHjx2P58uVYuHChL82wYcMwZswYAMAhhxyCpUuXlorcDBkyZACQImdBRBUA/gjrcvh6ALOIaDIzfyRFfYyZL5PSHgHgSAAH2q/eAHA0gOlx6QnjAEqFLl26FH5Pnz4d06ZNw4wZM9C5c2ccc8wxyrMSNTU1hd8VFRVoaurYstEMGTK0P6TJWYwDsIiZFzNzC4BHAZxumJYBdAJQDaAGQBWANalQmTK6deuGrVvVN1Ru3rwZvXr1QufOnfHJJ59g5syZJaYuQ4YMSaGjXzqaps5iEIDlwnM9gMMU8c4koi8CWADgh8y8nJlnENGrAFYBIAB3MPPHckIiugjARQAwdOjQpOlPBH369MGRRx6JUaNGoba2FrvttlshbMKECbjzzjtx4IEHYu+998b48ePLSGmGDBky6JHmYqHSMchr77MAHmHmHUR0MYD7ARxHRHsC2BfAYDveVCL6IjP/25MZ810A7gKAsWPHttt1/eGHH1a+r6mpwfPPP68Mc/QSffv2xQcffFB4f9VVVyVOX4YMGYpHx9Cq6pGmGKoewBDheTCAlWIEZt7AzDvsx7sBHGL//gqAmczcyMyNAJ4HkG27M2TIkKFMSHOxmAVgJBENI6JqAOcAmCxGIKIBwuNEAI6o6TMARxNRJRFVwVJu+8RQGTJkyJChNEhNDMXMrUR0GYAXAVQAuJeZPySiGwHMZubJAK4gookAWgFsBDDJTv4kgOMAvA9LdPUCMz+bFq0ZMmTIUCwyBXcRYOYpAKZI764Xfl8D4BpFujYA30uTtgwZMmTIYI7PzQluLfKtwIZPgZ3breeqztZfygE13YDmzUC+DWjb4Q3rtjvQsNx937oDAANdd7fSyLr8ndvd9K3NVnAuB1RUAzubrLDqLkBFpZWe2aKNKoAufa1/Jpj/PPD6b4G9JwBf+JE3bNpPgaVv+NPUdLPK27kdOPZ/gOFHu2Ez/2yFHxRyYry1BXj6EmDgGGDWX4F+ewNnPwhUCDf3bVkJPHWx29ZR0bkvcNb9QGVNcLy2VuDJC4DV7wGbltovCRhxHDDqTGDOfYpEBBz1Q2CfU7yv3/gd8Mlz3nfVXYCv3g107e/P5qNngLf+YFghWONm9XvAV+4CRp9tlmbjEmDy5UCnHsAn/7LGSNfdgOHHAJ26Ayvm+NO0bAdaGoEDvg4c/7/u+53NwBOTgO3rzWkGAZuWAEPHA41rrb8n3ggsmgZM/z+4Y5+Ao35gfRMv/Y81nreuATZ/ZgUPPjRCmQpU1ACn3Qb03dP7fvX7wJ1HAYMOsb7VXBVwyq+A3Q+wwndsBZ6+FDj1N24fPv8Tq93qZ1vt2nek9b5XndXXovZ6/SLg2SuB/c8ANi7B8CVv484qQt2WLcA93dW01s8CBo0N14KP+hqwZQWwcbHVtwPGWN9Nrz2C0/XbBzj9juA4RSJbLAD15NXSCLRsszqX8/6wDYvU6beuBEBATVf33Q77nAXngVylm1/eyZeBndusfw4qOwFtLdbvbevMF4sFLwD1/7FolBeLeY9af/vv677bvMIayA4+fcW7WLxgH7wPWyyWzwQ+eNL6B1iTyYo51kTiYPX7wJLXrI+mk+aj0mHraovOLSuA3sOD427fAHw8WXrJwKcvW4vz2o+BIeO8wUteBxa+6F8s3v8HsHUVMMA+H9rUACyeDqz9SL1YzH/BquceR5jVy2n7Zy41XyxWvgMsfd195jZr3M2zre56DHEnO8BaKNZ+aP1+/VbvYrFlBbDgeaD/ftYGyASfvmL9/diWDG9cbC8WL1t97oyfpW8AC14Eeg8DPpthleEsFIC1aerSz6xMGTubgGVvACtm+xeLR8+z/q6YA9R9wWqrz2a6i8W8R63x0bW/tWAAwLsPAVWdADDQ3GBtkDYts/rntNusDYKD+llW2Q2fAdvXo8vO7ZhQAWxu6w7UDPLTunGJ9XfTEmDAaH2dVr4LfPiU9S05WDXX+ltZ4+1TGSJ9KSFbLHKVQLcB1oQAAN0HWQvE+gXWc0UN0GqfmO4+0NrFrZ/vzaO6qzU5F/KsAPpYA7ihoQEPP/B3XPrNr1gfRm0vaycppm1WuCLvuht+/+tf4qLzv4rO3TrFqJhmBzPyRGCisPOd9Vfguf8XI/8icMqvgUEHR0sz7zHgqYuSKb/3cOCbT3nf3bqXPv6Qw4Bz7Yl42VvAfScH59+1vz9/HX53gDWB5lvN4ptg39OACTe7z+sXAXccoo8PWFzVgWeZ5f/THt5nqnB/V3d1637r3t54R/7A24fHXmdxwHGwcQlw+5jgOANGA1//G/DrEWZ57nGExRkCVh3evA2Yen1AArbmDxvzK/fGOFW///vXwCs3ASOOB868W5/d30+3OD0V9jsd+NIvwuuQIjIX5YEoXmPV0NCAP933SKy0v7/nYWxvinhVakHLpqDdSAOXopYuCQ1g0XUICFPmrYmvpSNqHWO0SZKa1ETy4oC8OF3Nr2neofGijAt13HBKyvz9FYmMs0gZV199NT5dthxjTjwHJ554IvoPHILHH/47drS04CsTjsXPrrsG27Y34azv/QT1q9agLZ/H/155IdZsY6xcsw7Hfv176Nu7N1598+1yVyVDhuLQ7k+ttXf6yovPz2Lx/NWWLFmFthZLUQ24SmhHD0EVlkwYAKpqAZAb1mdP4IjLA4u95ZZb8MHcOZg79VG8NHsRnnz2JfznuQfAzJg46Qf491v/wbpVyzFw93547oHbAQCbt2xFj6Gj8Nvb/oBXn/gL+vYfEFiGFyG7PPmDkD/gVO3/WF2mCaKkCaoDsyYvgpYb88R3fgdxHOWedEL62ANBGR0XIjfraSqywzRlFLN4UEg/FMoziQfNuNCk1Y4vXX1M60kpf3/FIRNDlRAvvTwdL02dioNOOhcHf+k8fPLpUixcvBQH7LMnpr3+Nn7yi9vw+tvvoEf3buUmNUOG5JFxFkWhLc9oagm+YTNNfH44i5Nv0YdtXWNbMQHoM9Iyt3OU2JW1roJbDivAbJAxM675yU/wvdMFC6FOvYDmTZjz/EOY8sobuObmO3DS0eNx/c+KVWaZ7JIBP+2lkC/H+ShJyiOwoJAwRfmk29WxP15Y2eWeFONwYUnQ7OOqwvqsmDINxgORWy8TnYXcBto20eksNPFN25Y03K0ddvU/3sMTc+qx9JZTzfJLGBlnkTK6deuGrdssk9gvnXAs7v3bfWjcZomxVqxai7Xr12Pl6nXoXNsJ5595Kq66+Jt45/1PACJ069oFWxsjnklox2xsh0I527nd9bGhQUG5F9FQaOhrJ+39xJz6spb/+eEs4sJkfPviuC/69OmDIw89GKOO+zpOnjAB5517Lg6fOAkA0LVzLR68+w9Y9MlC/PdNv0eOcqiqqsSfb74WAHDRN76Kk8+/HAN265+ggjtBuXFsElLWWcTKKyB/pc4isIAoxESIGxOl7GOxrDAuNhGdRWCkIvOMll7LWRTeh+UXFO6GMTPKcXFotliUAA/feaslyuoxFKjtiSvPOsYNrO2FEbt3x5eO8R/iuvw75+Dy75xjHdAzRpiCOyx5CRTcaecRpuCOkndUE9nI7RenTZLsoyTNmVXtl1AZ+sKTiRdlXIhxI/V3Mt+f1kYjZWRiKKC967UyZOgY2FXFUO0M+TKJxbLFIiqK1skVx+qGgn0/hDATBXeKKErBLecRGCkkTKfgNohfUJgG5J/2pBjWBlH6OBEFt8jNyiI7FtoqybFXQgV34KE8Vr5V5hOGEAV3aDkpo8MvFlySVTiNySGivLSdKOEyZNAi4ywSQcZZpIBOnTphw4YN0SbS0F1Z+xtQzIwNGzagU6dO4ktVTOz6h/IS0FkkcigvqOxyj5ESH8oT81IquHWH8oooqqSH8hRxVb9TPZQnKrgNs0sYqSq4iWgCgNtgXX50DzPfIoVPAvBrACvsV3cw8z122FAA98C6mpUBnMLMS6OUP3jwYNTX12PdunXBEXdssbyJAsAGm3XdutZ6rqh2vb/KYQ6qtlpeMB3kKoFNgnO1rautPNa1AVVrgM1C+uptlndbGevzwLb1Lg0bgqvQqVMnDB48GJiXcRjBSKp9ytnO7ayPTQ0KdlnOon21d4dbLIioAsAfAZwI6z7uWUQ0mZk/kqI+xsyXKbL4O4BfMPNUIuoKIK+IE4iqqioMGzYsPOJbfwBeus76/d1plqviJ20PnAMPtlxCA8B3XrJcjz8peecc+SXLvbWD7oOA/ydU887/slyNnPFnYK8zgZsOd8PGnA/MfdBP09kPAS9+w/rdfz/g0hnh9TBBOXUWRZWZJJ0anYVJfJMJL9KkmEL7x+njxCbyIC4sBZ1FYBSKVi/jQ3lqhB/KC8kvqDyPzqLjiaHGAVjEzIuZuQXAowBON0lIRPsBqGTmqQDAzI3MHPPGnM8ZMq+zCKxDZLPaqCayJTCdzbzOCtkb5m3kddb0UJ5awW1ARCJx8mXiLNJcLAYBWC4819vvZJxJRO8R0ZNENMR+txeABiL6JxG9S0S/tjmVlCDvHDU7STms2LIUj8pyE0WCB6N2SQTpLDSIfCiv3IjTx2lwOPJzqcdexO/VFzUNbqv4PMplzJLmYqFqIbmWzwKoY+YDAUwDcL/9vhLAFwBcBeBQAMMBTPIVQHQREc0motmheok0Ecb2a00Hde+C3odhFziUV24Ftz4wQvwgjiPtSbAdH8pTGkwkqUR3soowHkziRRn3GgV38S0ZpOB2q9wROYt6WMppB4MBrBQjMPMGZrZ9g+NuAIcIad+1RVitAJ4G4LtajZnvYuaxzDy2X7+Y1zMC5d1d68r+3O34S4X2paz8XKHdj+n2TV+Bug64WMwCMJKIhhFRNYBzAHguRiYi8aKGiQA+FtL2IiJnBTgOgKwYTwmyUowCwlRxELwAGCsfix24cQ/llUK+XISCOxGdhUrBrctbPpRnUHa5J8WSH8oT81J8O9p+T0DBXXavswams4kfyivPapGaNRQztxLRZQBehGU6ey8zf0hENwKYzcyTAVxBRBMBtALYCFvUxMxtRHQVgJfJ8pg1BxbnkRI6EGeRHc4rDTKvswIiivbaLUwV3OUB2W70yyWGSvWcBTNPATBFene98PsaANdo0k4FcGCa9ClBhf/sZwMFd6h3TfFHqTgLHdqBgjvzOhszbsw8S6ngDvI6m6SC27hOURTcxXE+rKWJpL9aAozCOqKCO0NZsAsouNPOo+wK7iiI0ybtTcEdkJdHwZ0GklRwm4id4O3jEnqddajriAruXQfyzjGyziJuWYrnsPfFol0cyisndDoLs11d2fURJijrobygcks89kp8KM8435h5uD4sM86i40CnM44k/ihWZ6Ha5RllEK9co6zbi4I7SliMQ3nl9jpb8rxEblYx+FMxJ44yHkziRRkXagW3/vIjQwQpuAGQnX+5VCjZYgEg6YG8YVsLps9fGx4RCOAskqMng4j2oazM0B6xa3x02WLRXhB4ghswGVDbdrRh0n2zVJkr0qek4M68zurDMq+zApI8MCe1ldhnKpFQIgruoPEgfm8GOgtTeiIfyjOtJwVkQoVsMhfl5USHOpSX7ZyDkVT7lLOd21kfxzYoaG8wVHDrUKKqlqtFs8XChzgKbu87n+yyYDmnSl9i09l2oeAuQmeRVvmZ19mkCg/4neTYM6xTB/I6W7CGKpM5VLZYJAJ/5+XKxaxkXmfjp8+8zsbNJCAvTpe7KIvXWTmdhfC1pczfX5HIFgsA/p2jTmeh2h2pUVmhadpym862h0N5ZUWQzkKDzOtsTDI0HLYuPHkCFIUGRU+L604iH9d0NtNZdCAwCFUiaxHYt0mLodjzRxkWmLwEA7HcCm59YIT4QRxH2pNgezuUJ3CzOq+zSS8MkfMrpp5mh/Lims4uWb8Ne133PJZt3B5yKC8znS0/UtjhVJjKoTKvsyVG+2XzM5QbxVogxku2YlMTWlrzWNnQFBgv4yzaHeIouL1gaMRQpTiU56FCfqXa4cnPn4dDeRoFt5HX2VIqi2OibF5n5bLEPktJwZ2E11ldG0T0OsvaTzm4ns7kzzrzbSmPzBpqF8Y7n23yvassl4Z7lzJVLAcSap/M66yAiKK9EmH+6i3Y67rnI6SIo+AuHu5iEYyCIDbjLNoJQhXcfmxobPG9qxI5i0CrzDKLocq9Cy4HMgV3eJpEyAihI+Wxt2Hbzmh6hDIpuIMMGFV5ZDqLDgQGaXQWpbC/DzFjDE3+OTjBrQ80ehUYkCm4FWFpKrhN6S/m4KCZgjtuv3s4i8BrVcmOH6uYopEtFoB/55iA19nKiiIV3Gnh88hJeBAuE1YEGsZrJ8i8zgKwNm2R5tWiD+UZ5ivBmfyDGQtRZ9EBxVBENIGI5hPRIiK6WhE+iYjWEdFc+9+FUnh3IlpBRHekSWfSYJBXZ1HQ60bgNuJ+vB32UF6SCu4oYTEO5aXOWCR5KC/BTErqddbJPsjUVOQAAjOJWIZawV0sZ4EgBbeQez4fq5iikdpNeURUAeCPAE4EUA9gFhFNZmb5Lu3HmPkyTTY/B/BaWjS6SH4gV+YM1+FdYafaodDelMPtAxu27UCfchNRdpTnW3Tcd4Qqrp39UgfkLMYBWMTMi5m5BcCjAE43TUxEhwDYDcBLKdGnK1j/HOkEtykXoXtXrM23gRkooJExp4X2oLPQla/Z1X1OvM7+6In3EihX4qrK7nVWPCgXw3Q2onVU3C/HFUPpzLctWlxrqJgFFYk0F4tBAJYLz/X2OxlnEtF7RPQkEQ0BACLKAfgNgP8OKoCILiKi2UQ0e926dfEpTWF3X77pIts5ByOp9ilnO7ezPs68zhaFqIfsOuJioWp5uZrPAqhj5gMBTANwv/3+UgBTmHk5AsDMdzHzWGYe269fv6IJthCkxDZXcDftbMN79Q2FZPri/IH6i9+BOcs2oaW1CKFlu/A6W24o6iwqEJnx9uINgljgc6DgTmUctAcFdxGms0n1tfGhvKA8RGuojieGqgcwRHgeDGClGIGZNzDzDvvxbgCH2L8PB3AZES0FcCuAbxHRLSnS6sFbn24oKj2DsGBNIybe8SY2N+10AwwV3Pk8Y0tzq+/9gjVbceaf38Ivp3wcUPiuoOCO8xEWBLYmBRnQoA97eu4KnH3XTPzznRX6vDrgtarxD3uVQ8EdxeAhLF7IuNQpuKX3cX1DOdkYLBmGMdJBagpuALMAjCSiYQBWADgHwHliBCIawMyr7MeJAD4GAGb+hhBnEoCxzOyzpkoO3p3j6i07PM/e39EGxM62EC5AxVmAsLPNPyScw38frdoSiQapwNDyOzZ0k7n7btmG7dbfjdvlIPmhnSJ6HzMIeQZMLb7NyAihowRjryjT2RIdyjPjFDqw11lmbgVwGYAXYS0CjzPzh0R0IxFNtKNdQUQfEtE8AFcAmJQWPaZo3NGKGQlwFg4qiIQRW5zpbKRzSEUcymNmPPfeKrQFnP5ZtLYRH6zYbECIovxd5VAeszb+6i3NuP3lhdi2o9WfZpdYUBy49St+EtItxNb7YjY5jTtaMfWjNe4Lg/HgPWWRoF7Fji+3lwlnsblpJ16dv9bzrqDg5iAFtzuqOqLOAsw8hZn3YuYRzPwL+931zDzZ/n0NM+/PzKOZ+Vhm/kSRx98CTGuTgTDAb57yMWYuKW6xEJELmxg14a0KY2r384gw4cXAU++uwPcffgf3vblEG+eE376GL//hjaLLKj2S+dJu+tdH+O3UBbjmn+8nkl97QNDmIBCGi/PP/yVbzZvjJ0++h//6+2wsXtcYO49wmCm4G+0NwqbtO1SRA3HZw+/ggvtmYe3W5sI7Y99Q9lyR+YZqJ1je0CztEKTfhl5nlTDUWTAIKumVO1hCSVBTYeh1dn2j9RGs3tyMRLGreZ0lx5xWr+BetmGbv+xyi/aiFC9MVEVzFr62Jc97/87bnNCldjtv29GmyDuAJKN4Go5X049t9kau1ScqDpcSLF5n1UM0UmHPYqGhM/M6216Q3scd9wCN6sMteFsOLLD4oVS4ZKXonNojkqlVREcSRvjbm0vM7lcO6eOPVm7Bqs1NePnjNViwZqtx+fF9DsVLuHyju9A2tbTh/reWanfN7tjXl/Xq/LX4ZHWwqOupd+uxpXmnJtRMwZ20VZLY7ttb2rTxHOryecbjs5cXNnWlQpoK7l0Ymp1kDAV3qAhbqeBW7VpEmWUxgzR892RyBcAujSS9zibIRfz02Y/Qq0s1Th+jOo5kjn+9vxrP17+NJeutyXjpDUeEprG42YQ7XNoNs3Thw+WPzsPTo48BAPxyysd4YOYyDOldi+P22c2XVc6Aq77gvlkAgKW7O2V6v9fNTTvxw8fm4aqey6CUaxsquKP3uOIbF+pREEMxsGpzM0Yot/BuHisamvDjJ9/D2D2B5ZwwAAAgAElEQVR64clLwvs2KWScRQoQ2W1pT6KIrdFZxOUsCgXHVXCLP5NeLYpRcEt5BBaTvDJTT45CKV4Ep7qlSbfr9RQSGiPs1jVVXkZcjTILJ51CBGd4udLqLZbIU2UFCIj6OudFFGsPK16rLdvdukNq41DxqNp0VuYu434t4gnuII7VqbKzkXTarFTIFgtA2gGR9P17J/5731qaWtkiDa2KDzeazsK0PH/5ql3cZs0kFsTllEsRF4wAnYUvqmISMVjo1jbuwKe2Inbm4g14dp7neBEWr2vEPa8vVqZV9Xt0yFyCqels0v3llpvP+7ce4vMOW4ZfXRk8JZmMKe1YlahatbkZU95f5UYo06E8kzrtFHWYZeL8s8UiAj5ZtRV3/1tvIeTAw1kwC6PUnLNQKrjFPA2o8L8yS+eKodz4N2sOAup2ggCwYK1kudJuFNzBYeShL9oXmec8VjY048w/vwUAOOeumbj8kXc9cb5+5wzc9NzHaN7pl0+rxI9x0BbjsJpxmsC81Ivu9p3B541aWq22qFFdRwwUvh2XQv142NLUascQ2WQuLIbO+J760Rpc+tA7iNrHet9Q8RaXgiNB6HVhljcIb/6Jiw1DkC0WADzcQ0D7x/mYQlNoLS4COIvAAtMZQKqJDQCaW/UKufbLWaSfj253CwBbFafzHbSEHeIEjPo4TtPHd31tYGkUAoezqKlST0mJnDFwZViaCGYKbnfLk6yCO6hu1ZU531RR6sN52WIhwedPRlJuRt3X6kRaYe/mLPPe633btIWFdyZjpHmnakJS7PwUMmZHDHX/jGWelOpy9IuFyixXWaaN3740H+8q7jN/69P1mPyeIy5gvLZgnVaMY0XRN9DmphZP+a1teVz39PtoaWMoaxnR6ywzK0SZbtj/vfBJ4IKQBGfh2+EaeJ1lJHso76G3l2HVlmYs2bANjvZLpkt8dkxJKzSu/d3rYeQxZLBwggo0AIoe1OpVdIuHrv/U8Xfaq4HuW3HPWZB2dHWurvRYQ4npSoVssQBStYuPqyR+eq5Xzv27aQsKh5pMDuU17giaxIMRpTmSEpsAwO2vLMJX/vSW7/15d7+Nx2fXF56/fe9/cNNzAf6xAtCwzXtf+uxlm/DgzM88CmGTPouzq8wz8OfpnwbGaTPa3qczSSR5KO9/nvoAG7e1YJGh6a6zWOhNZ+Pr65w0shhKUYouB+WT6Wfy0UrLnPd9jccDcdLXjSsSiHYkHKW+XjVbLCT4d0AyZxFxYdGIccOSBKGom7IMdk8qcnUfadAEU+6zaXr4xY7Kfi1UwFzBHTSZ+dxDKOLuTGAGUAgwDdIkr+D2cxL6cEcMpaMgqu2TmL9xe/g+DXW8qM1UYeth8jKTaiNvsPowBN9QdoJMZ9GeYTz5aUxnVSNFx+kGFCbmOeX9VbjyUUGBWlDShiu4mRl3vLJIyjuvPfuhQtAEo2X3YygCnZQNRi4WgmiSd4nu82cbtnkV+ewVTf1+2gI8MHOpnY++bNO2UsXcaeJ+PoFJ/Zp/vo/HZy33KrhjTz6i0N3bMgTWK74FhHMW1t+8PLMyo6U1j3PvmhlCIgdY8VoBD73tvRHhhQ9XF9LKeVkUqDkOGc6tmbr2Fa9V1XEW4lhx8olt6hwT2WIBQJ7ctRM8Rbd4iMU2G8jFHVz60Dt4RhBZhYtQvLu5eTJrzNGm8qDxGoWzMFWGv/pJEZdcwaqbcjomYP6arfjLvxf7Jcd2RX4/bSHueWOpJ8i3Ww6ohmbO8SAJ01kTncUj//kMP/6Hezue43U2SQRxEnK44wtN135BXgUWrt2KGYv1/tyccsM4pxUN3nMLL3ywRhkvqmi5ssBZaBYC4bVeEEaFNmjNdBYdB95DeRxihaFhdWOa4RV2T8oBHS4GYWblJK+bzKPtRrVbu9BF1WmPHBmUF8TtEGsnRRNuzKBwbd/JbaXKWeVAMl24VKTpdTZUtMrevz7IlrKCglvXZLLXWffbkMmLVm/dt6Dr90pbOy9yAp4T3MJ70oxvUafu9FPRps4RkS0WQIQtcAzxSQr96eT5vHCgyPEQG8VcVfcJ620y/Igywby2QM8VmOaThB7k3wvW4eWP7V1jzP6RF5aG7S3Y//oXAk1m/ToLf+EmBgP1m2TnhdFw8QNzlO/Fxey0P7yB+99a6ovjuBBRoXFHKxatbUTd1c8V3pl2l9M2Z/1lBpoU/pHcpcHfPlEXuQbtoT01td++9z/eeIXi9OU+OHMZjr11OgAgl/NzNnlmHHnLK3h89nJhgdS31hNzlmPTdss445dTPrHz0EZPBdliIcF/FWORprNigFJnodIPBJfjfDA3Ci6ff/asYynlUKqBUF6eFaIBZsFMUSxTjaAPNSfl/cIHzuJmrhNxw600JoxFmM6CQbj5ea83fL3ZolferptQ3vlsE7a1tKF+4zZtHPnjVvJ+BvULu8nRn4XUD44sXipQ7Mv3V2zGDZM/9OX01LsrtOWu2NQkcdUuO6C64lR8FnfXyzb6FyS/payYdzAYBPFQniqGJ2upKB89BpzFdU9/UFhYnehtgjowz1zw8WRiDcWgghGAgw6lsyCiCUQ0n4gWEZHvpjsimkRE64horv3vQvv9GCKaYV+M9B4RnZ0mnXE4BlMkcTBNJxfv27XGHzeCGEMnQtLdXxMlD20+UO8OTZupWM7C+RiL7Rf5oy7I1AN1FhJnEVfilJL4wWToVOuu0mP1EmlqYiwOI9WyHaSzMBWFmoo6/WWrYToUnWLzgpJdXCDYYLFQocPoLIioAsAfAZwMYD8A5xLRfoqojzHzGPvfPfa77QC+xcz7A5gA4PdE1DMtWkWs3LzDO2h8B7JiKLiFJPI1qyrRjG8IaE6Q9ularU3rG3QKSyRW7Mp0k+hz769Sun8uTDCKdA63AwDH/2Z6oWSVmCFRMVSIhRYD+HTdNlz1xDyIn6nTZo/Ptqxibn9lEeRDeVqROoXFUOks9HFf/WQt6q5+LtadIvEO5ZGRDLxK545DyMtPR4giAuH975zV80dj35h15P5e01n2fRuFb6RwKM7FCx+s0i4eTnkmE3vd1c/hjletszViHds8OginJqYnPbzpSgWjxYKI/kFEpxJRlMVlHIBFzLyYmVsAPArgdJOEzLyAmRfav1cCWAugX4SyU4HprlavnCY0Sac4Zy72n1j256GWdVcrPtwoO2b1jow9B4BEvPLJWt+7oI+8Ubhy9NN1Liu/vSW+ErdYHlD8wJ+cU6+Ms8LAY6vfJN/lLPQiO++zqumcpn9w5jIA0FxdmxJnYTB2KnWLBXNhIRbhtHd1ZUVgvmHcgcNZFGiMcRlQWP3Eb+6+N5cKZas3a/70wRD3HWJ9XYV1NM6i1DCd/P8M4DwAC4noFiLaxyDNIACi4XK9/U7Gmbao6UkiGiIHEtE4ANUAfEdfiegiIppNRLPXrSvCpFL2u+8N9MSLa6VUyN/EjD7AxBAIZqfDPgixeKXOAtEmZIdTijLEG1taXedpzGjL++XJ+bx/x4iItOmg6sPgftXrLGQLmyBuwSeGUpXkTCZ2XNn7RVueI4tTzO5TIiMZuFYMpaTDydu705fDrTju76CLv1QHG2VuXb43o8BhSHTIJrVBN/lt3u4qxbVnQZRvXXrEVF5ld3C+wbmXDkaLBTNPY+ZvADgYwFIAU4noLSK6gIiqNMlMJN/PAqhj5gMBTANwvycDogEAHgBwAbN/mmXmu5h5LDOP7dev7IxHAb6PoMD/Kk7JatkV932b/DEoyvGUB70Y6rZpCzFveQMA9Uc597NNWs5Cha/dOQMvfbgaz0huuFVwaPrt1IUYfu0UNO9swz2vL8GIa6egYbvXQmX4tVNwxaNzXfId01mzERtKQyEm68PC8vLkW1gt9Kazfs5Cn7cTV7zDfcn6bRhx7RQslL35huALv3pVH+gRjbgLuA5BLsQd4wF/Efo2cSCOxZNve11vnlp4beX35JzlOO/ut7X0iAl1a+HJt/3bX470PPrGl3DvG0vsrDS0hU7orhlFq8eM1vqdR/B9FuWGsViJiPoAmATgQgDvArgN1uIxVZOkHoDIKQwG4JlRmHkDMztHcu8GcIhQXncAzwG4jplDjmcWixQV3FLnyxO0yUZNdgNe7B0Sbyxar6QFsEQw+h2S+v2bi9YrRVQ6zLCteZpa2gqioFUK2bx8DwSQhBgqGThycWcuNzE3lnUCQT3l9KO4WDg+hqJOKBskf1g6hJ51gHsa2Q/9btuEWnksymNed5VpkClvWBkOVtqH8XR0Ou39rr3Jkt+bwhJRso8W53c+X6zcIl2Y6iz+CeB1AJ0BnMbME5n5MWa+HEBXTbJZAEYS0TAiqgZwDoDJUr4DhMeJAD6231cDeArA35n5iSgVKhbyVYy+i5GM87B/Cwla8nmfjTcpPj5/Oeon1dh3lW/+XJ28HQVzW96/4yPomZ2mljZs2+H3Ztujtkr5XgYJNADAxu0thbI2hNwn7LDyImmNujIDOokkQdv2llYhTFkwmlQ3z7jB1ltBwa3lLGQFN+snMGeXn4th/uUTWwZOQVz4vzBpBWw4qoI4C5Lr7op/WEGH87y+cYdvgVokcU9OSqddttu6P7PWsZas8MN7weLfwnsdZ6HzJaV4l/foLKy/rflg01kVNm83uVkxGZhyFncw837MfDMzrxIDmHmsKgEztwK4DMCLsBaBx5n5QyK6kYgm2tGusM1j5wG4AhbnAgBnAfgigEmCWe2YaFWLgFS9zrq49YUFOP43r3nCK1SHGsLyLGTqH1gmnIWjZNdF1TXHHa8uwv43vOh7f/sri5QXzYctrcf/5jV8strySnqR5qCYjLVb3UVllIKWcHhpcstVV7o1z3hs9nI89a5XGe43nbVzD6iyHMZgBUfl3UGLewlnV5qWqKLgcyhIDBVgOqtqQ1JYK4lYuGYrxt40zff+lNtfx0LBY62rs7D+Hvizl7R56hDJTUfARgyFfohavsuBimIor3I/Wt+OvjF6O8RFpWG8fYnoHWZuAAAi6gXgXGb+U1AiZp4CYIr07nrh9zUArlGkexDAg4a0JYywQ3lRTWe5kMV8hbvmHJFvfPiGi098ESCG0mk0BPNAZ2LPK0xnSZCrtkesbzQxJQ3SWWhCST0J5215+2vzLQMK3bzHil+qvDxpWB/b2QXH4SwiTWOCcreg6I2w4Emh0pOsWJZjExas0etfRC7cqZHchqo+U5rOCmccfKazEsdr/fZziC5HH23RVs0ZImchcuVRTGdLDVPO4r+chQIAmHkTgP9Kh6T2C9NPUBwc9Zua4IhfVR2umwyCFiVnIlm8zi+vFXdxjjx3Q+MOrBUm2c1NLVi8rjHaobwYIADLN273iaiiDPy1W7zyZPlUeHSaon12TmkqzkmEqxwOiCMF6lyDrGxoQkOTV8/Q2pYviGaSXMo3CvoMZyKu36Q3HdbrM/Sms0H78JY2fbuK41PWWcSR7jvuMkwQZPgQvBUJylPgJoTf22xRKHcQBXeOBBMZ+8Cd/0TYLguvjsHTXR6vs9G78lv3/gdL1ul3TzmlGCpcdrpu6w4sVij3xEF+7K3Tsb2lFYfcNA2H3/yKnRdhyvurcdxvXsOW5lZfWUnjC796FeeEuY8OwLhfvux5jiO2kxHddNZdLLROAg3Ef7I45qTf+a1wiIAjbnmlsON2dqC/m7YAv5+2MLQMFY1Bdbvcdm/PcA+KnfDb17Txo4hyRGmpWmcB7GwN4MSExcLpdpPT2jrT2W/+9T+e5yj3bXjzDyVBmY+YTqxH0DW7YbSUEqZiqBcBPE5Ed8Jq04sBvJAaVbs45LHU0poHcuoOVy8W3rh+c0/WKpRlBbdzT4BqmVPlQeDEdTjODWGygjsKnDRGZv6BJ7ijhTnvREW4Cu7EZm46awJnEZq3XH3LWrEQKTU5lBdeB5XpbF75HgB2BFwx612AvRNuwVeYcX9G4weCpW3qULEmOQpuK7Gtne/Q0mns+pzFTwC8AuASAN8H8DKAH6dFVMlRxivdjPQDCp1GpWLWfPnjNZFchsuHmRwksHkHEH/gL9sQz6sqM+ONheujXchkCFlk5NTNWQhNxFCzl6pP64uYtWSj59nJt1OV+6mmNaGoDuXN+HRDYcMxa+lGNOkWTdZvAYKoDbrsaWtzq+8u+ta81celhK5ecj/s2NmGlz9eg3nLG5QLhbj4iZ9eo4HOIghvLSpNexhxFvaBuD/b/zo0gr3Omu6KzfUQqg+Jfe8VilFFwu/ePxuP1TaiL9yB7AzagrWOQMOO1ryPJstwOJ3F0+UsgnH0r6f73jlp8gFH4Ke8vxrff/gd/OnoVpwSQEM0MZQV33FXolNW5gWlpywGcXDtU+9raXcgH7hz8q0JcZfhpVh+lumx9rCAl9tTidLOvXsmLjiyDt89ahi+fucMAMDZnfQlq7zOOofyVOKxlgDO4tKH3gEAzLv+pMIG5oGZyzBveUMhJyNGE2TEbYr0WWblvoysP5oxuK0lj/++f3YgLZ9t3F7I34EjcgzSWQTNO+fd8zYevWg8xg/vE1h2sTBaLIhoJICbYTkELAwVZh6eEl3tEuViEP0fP2s5iB2tbYAwrwRxGs071crFJBXcSSOoPittn05Bzvd0H2NUWmXxjTPnRZVnh8HJt8bDWaQDXdsuXNNoIFfXe5212kSdt8k1sjva2gpjMkj/lyS852/UW7di+kHH/cblGkWT8rRgKoa6DxZX0QrgWAB/h+WGo8PBdyBOmDmnfrQ2prw9IEwRKJfRtMMrAtnZxrhFuo9BhlOLT9c1ep7F4nbszCtoY3y8yu9dVoTKU67JIE9iklug8HxbyJ/CadGZzmp3dSzvlv2YPn8dpjmXKSW8pXDFUFE4i2DFrVhPcVfNDLxX34D4kCdVh7NQ+w8L4ywc7GxjvPih1b5bpEXL2HRWkUb+K7bbgjWN+m9dOm8RBlWsf76jdmIZ13Q2iasQwmCq4K5l5peJiJh5GYCfEtHrAG5IkbZ2B8s1RW1oPK0VheKd7lMR85A/kI3bWrwX2AiQP54gSyTZA66DP7yySJsG8N8cpgMRKytdjIJ7o8GJ1ShnAeJCbOcL/+6KHvwixOLg7EBFD8NpHsqbeMeb8RJrzlKEGTXIbj1UuG3aAn9xEcZQFF9nyvQFkW6wXioKTdM+9rvHMRPSasougdjDdLFott2TLySiywCsANA/PbJKDJ/XWb3OIek+MeEskoWos2hLuazyIHQXFrHOXpua0rZXHLcfUUxnPWUF+hwLT6/SjIhpVRyPiSluVBELMxWI6VZT6Vss4prOtsYxZ0sIURwxpgVTMdQPYPmFugKWs7/zAXw7LaJ2dei6TakcNdilxFmi5JJUeTTv9PM1cZdDMzFU8C4zCDpTyTnLXOuhwqQQ0xoqia2AToEeF84kEHjnUETozDeCRBnvfBZuySUruL356kQ64blWKBdKezyE3LNbWUG25+d4Y0KEa/HmmKMnjfimJaXgLEKHoH0A7yxmbmTmema+gJnPTN8TbHkgW234fyc7RNScRXyETXhifZp2pstZlMJm/Mw/zxDKC4d7otgLnRM4QDUGSmcPr7ugKgjh1lCqNIQg9cF1T38QmoPKctCrI/KHm7RiMVIk7WVNCug4Deetw1m475MfA3GsoYB2wlkwcxuAQ6hYwd8uCldxGR9BDadSMUdJr08Tnq/KGipuJ5tO1MUiCgcTPUyBiB9h0hOIs1gkKQJRKbgBs1Popvl6wPpRXvxd6MH0VJDLzwbFM0Fb3mvyZpouyjcVd/yUYutiqrN4F8AzRPQEgMKJKWb+ZypUlRjvftaAgzRhrXn2mKKaIEjnISOvscmP2/lRBqZKDFUKpDWwTbYzURdD3cHFoHySrN//vTAf1ZU56ZrPdPCL5z4Kj6RDgILbClJT7XgdTgtJuIdxJvA3F23Aqs1NwnsviuXSi3Lh2R7EUDZ6A9gA4DgAp9n/vpwWUaXGX+0bsAA/ayybTSZvOusP9R+Ui6OzYOWz+NZScAeni1ueOk7xMDqEFXBwT69TUJvOyre8hdUy6Yl8feMOXCncGGiCKKazrg0OFb158J9HcA/l6VTZrxudxo62NIums9Zi4T2U5zed9dIbVO7lD7+LxuadnvRhiPJFxf3+SiGGMj3BfUHahHQkRFlQdJaDcXcpUQZbq1S4jsuJCz0t8RXcweWFIykxUVA+eiVvMmif/oPUxguuziJ5fshkvCbJWQDA7GWb8ErlWoyq1C+OccGI37ftRgxFRPdBQQ8zfydxisoMeWDLXEbSnaIyFElT6Szm3Zr3uvtoj1OQCUbd8CJ6danCtw+vAwC88MEafLcmKIW/fTc1tULHaMs8mik2Ce6//yP5fEoTcUxng/r+jSJ9DzE77svjmfRGL881na3Iqd2MmJTfnr6HMFqv+ef7OHfc0FRpMBVD/QvWfdjPwXIi2B1A6Ll7IppARPOJaBERXa0In0RE64Tb8C4Uwr5NRAvtf7uUmW4U01mDM0mBS9RXDx6kSROeh+9u74gy0zFDegbm76cpedNZwHLEtnxjE+bVb9bGcRC001QLp6IruB1a//iqe7jx7CLctCcNnelsEvkq+5aLNSfWWQiF909lob+LV3C78b1/RXqKQVE6ixLAVAz1D/GZiB4B4L8L0RunAsAfAZwIoB7ALCKazMyyFu0xZr5MStsb1unwsbD6YI6d1sTYu0gEm84mvRtSyRqjDLpvH16Hf76zovAcRp2Yd2ubzFlEq9v54/fA3OV69xClFpd07xQ+nHMa2XkQ4prOFmtdpEP0djUznS0KGt2bdS+3eiExLzM+bRZnYQYdfUFG1ckjnulsKRD3qM9IAGE8zzgAi5h5MTO3AHgUwOmG+X8JwFRm3mgvEFMBTIhJa9kRqJ4z4iwC0huGqPJQmWNGmYgqhV262VBO4uPS5/HQ258Z0BKww1Qc8IrDWTgQLZjaE3Sms8XgrLtmaD0Cp+m3KNR01l4snnlX7YvJQrw+bk+ms6WA0WJBRFuJaIvzD8CzsO64CMIgAMuF53r7nYwzieg9InqSiIZESUtEFxHRbCKavW6d37lduaA1nVUo5ExOcAfBdydxyIlWEeKVmlaZ0aC6U8NDi+Z9nM8hqU+o/PuzcAzqGex/rD3W4cMVm9HY3Kq0vJItypKCSZ45IjCzkU+xoJJUiGo627tz8OWi7V0MZbRYMHM3Zu4u/NtLFk0poKq33OrPAqhj5gNhibXuj5AWzHwXM49l5rH9+vULq4YR/ErslE1nlW8li5KABUC3adObzrp5Oy69XVqi3QHs5SxKazp7+piB+jiBC6b+PgulB1NPqaUxnf3NWaOLSh82RnVeZ4uHpAMrbI78Ztuq5zgI8zpbaSu4VXUOM53VtUlUzsKJVde3S2hc/Qnu8sOUs/gKEfUQnnsS0RkhyeoBDBGeBwNYKUZg5g3M7HgJuxuW3ymjtO0ZUbzORlGGq1BdhNOgTdt3onunKuFNtAmjMhev7GIU3A7U/oJMMkr/syt24k3C3LMc0En4VS7to0DnRcGIsyhhW4Yu0iGktIcFIQimX/sNzFy4BJiZGxDunnwWgJFENIyIqgGcA2CyGIGIBgiPEwF8bP9+EcBJRNSLiHoBOMl+lzpk7kG9P0+bBvMBPmpQd89zFN9QAFAj3JMQtW4VoWKo9FqrmElAfQ7CTI1ZCt9QYR5mo/axCYqtjfJAo/SjpKazNiojmM7qOB9de0cdAyaeg+P6hioFTN19qBaVwLTM3Gq7M38RlsOMe5n5QyK6EcBsZp4M4AoimgjrUqWNACbZaTcS0c9hLTgAcCMzl85QPSXoxB8yqipyxsNQ57LLxHRWRUuUIVnpmbBLazobxFmE+YaKVnp809m4CFoH/+eUfdGY0LZpaO/OoGLuOpKg000QpTPZmZjOOlxaXH9h6vjevyI9Jul0aO86C9PFYjYR/RaWKSwDuBzAnLBEzDwFwBTp3fXC72sAXKNJey+Aew3pSwxhXmdLscKn6Tdfzlk8ahG1bkFXnALp7r7DuBoddJN5sJbDz2mmWjfNajG8XxfkmUONGEwpExf7Ysc1AVi3dQe6C9mIuoJmxd0ppfiWcmTeU1FNZ3MRjEkCMzLIsz1wFqZiqMsBtAB4DMDjAJoAfD8tojoaonazz8IpxsSkV9NLZfmsHc3LEn0JmdQxSa+zsXUWBnmHvQtG8XVUiSv27N8Vj3/vcK31nAq6E72FNsxFM2gIQ1LiGiDYIuwMwbghzHS2Mhc84TvxoiAuJ5ILoOKk/XaLlGc5YGoNtY2Zr3Ysj5j5WmbeFp7y84loCm5d3Pg75ygQD45F/aR3tKqvZXVpUSMJ09lyK4HjnX0xg6puR47og75dayzOwjCf0w4cECjSSrINdY7AC+8j+h0bP7yPNuy8w/awyyqNgtvc6slf1m7dBb8zAaRUVebaBfcQBFNrqKlE1FN47kVEJVE4lxoMtULTDUtfeZim11l5xIqipKims327uh9CqU1ng912hNCiSBpkOqsbD4ZZR4aKs3BoMDng5tComyjVnEU6OgXxVxTT2epK/dRUJYggy2M6a47KnKt/jHI1roz2YCllKobqa1tAAQDsU9Ud5w7uhKHbRUVZaEq1y8izd7Ewxcj+XXHknn1jlZmE6WxlOzYvLd50Vh8WRQwV1kZptGEUrlqGeHamOkAnVVVooPZlOquip8LUy0GRq0EprqYzXSzyRFQQgBJRHdrHYpc4/Apub1ipaIiLqGaVrXkxzBxj63oXTUsxKG4SKEbBXR7TWedNnmXe1w+Rswi64DKXU4/zeFCZznqte8J27keOcDcfwZxF8LQlbtasm/LSMZ01gWexKGLIhs0Jpdg8mS4W/wPgDSJ6gIgeAPAaNFZMGfQfnqnprJyHbhgct4+euSMA3WpEYzc1VV6LJnPTPXngp+11FtIkHdd0NryE4vJKxnRWn36f3btrw2RU2IfUuZ4AACAASURBVK4uZJAQnuQUo6u7JcoLL0l0H2MihmJovg3hZWUKprO6b0n11rtYBLdBlHEjenwGgJP22904bVyYKrhfgOUBdj4si6gfwbKI6nAINp0tDXdhOnT/9I2Dfe8c6ogsU8uwvL2ms148dekRvvQ9O1f53unRPjmLKIu2HFbsbvOSY0bgmpP3CYwjTjBXHD/SEzZh1O448yC1W3qZxoocKcVWXW3vvLmETWf9dITpwCTRosAxVFeo7zJ+4yfHejiLAT06BdJVjNdZ8Uz64F7B/rp0iO5s0wx//fZYz3OxLmJMYHr50YUAroTldmMugPEAZsC6ZjVDCIodJLrh3qlKfzk4gT3bfx0N8lkJsaz+3f0f4tDendGwfbPvvUkdk1FwW/QFsd1xy0nCdDb0kBgRhvbuHBhHnMR7KxbnXl2CHdIV8tHsZPt2qcLaZra5s/ZjOivqKaoq1bQP7tUZ9Zu2F55VbulFBbbDrQSNiTD6hvSqRVOVW06UMZETuLck9Qpdarz1DpoLkoKpGOpKAIcCWMbMxwI4CED7cfPazpCEIjsJ09moOZiU6bDSpVocHHQU01mT2zRUVfMKC80mK4/ZpoCR/bsBKLHprMFoqPJwFvqpyRmDDAIR0K+b/lpEEwukniHeYIkYpxwwIDCOQ4+MUw9004UJ/aJ888VYVsWF6WLRzMzNAEBENcz8CYC90yOrfPArubys+q5iOgu4O5kJ++9eyON7R++pLctvYuiHPL9M+39HG9M4rG/wjtrBoXW9tGFO8VUB1jJxfCeZms6GLYG60IG2uMTEj2HYgcOwEcggPP69w9Gnq3oS3Xf3rgBsBbiQpljoctAtGHJbiGKoGkln8cz3j8QnP5/gK4fAeP3Hx3o4DCelYzoL37h2OY/DhvXG4F5qUVZXwcnm5cftibeuPs5XfhguPWaEK7pMUMFdjs2SqbuPevucxdMAphLRJuxCXmBLjWgKbh2S+3j7dHV3TkGTrG9XqIjq7GicMJPb6Rx0r60CNodPTF5PuA5t3jRhFjFBiNqyUS1NVPXrbIsNwm2Z1PqYqDR3rw3vl5geUwJRjOmsODbl/u1cXeETtVgLPKFTlRW2pbnVl2eYbqtbp0pUtarjdKmuBJqtpSaXI/SoDdbXqepIRAXvzEGLBRvxnC7KwVibKri/wswNzPxTAP8L4K8AwlyU76IINp0thb1w1F3e0Xu5d3l4dlD26BQtS4i8Xa5T5usgD9Joh+PMWi/PjFMOCLbuqCxisYjavofWuaeJ45rOOs3EHM5diCKGccOssk8UrF1MqDdZTCsEF/M6ksIuYnJpKt501iOGkjiLnMYENWy3LprOOsYZouksszuWfBy9XaZTdGzRDzl/4s/wBwzqGcmyKg1E/uKY+TVmnmxflZpBgSh6CG1c4dtzYnSrUe8W7//OOOV7sjOprsy5rHfg7sY7nFWD29VZWH9NvHoWkDeTXzOAP33jEOkdCaFAlWaRuuSYEfHFdop3OWKMlswUdRjWt4tdtj+nXEHOHk6bKIbab2B3LL3lVBw1UjgAaTBP9A+Q4zvJK3Lh/fbTifvj64cMDi3v118bjWJNZ0XRk7wJUYnmxJb2LCBCndxFhvHAdw7z5ZFnRpVmFpRLpMKkrzOdDREfhjRBUPpvHr4HPvjpl4IzSBnxt2cdBLIdul8v4eUyyum/xWQz4aHcfqjx7DKLFUN5n6NwFqZTuMkpZV25RuIppQJZXw+Ri2HFLweyA0gRBXo5fMEIvVMqhDVhELopRHkOnH4Vd8q6+ufIbNypaJb1QEH6QMBr0SNfrKXr7zBxjKhzUtUjL3IWkucFd/fOdlnFffvFpM5RDrXV6Vs8BdJQ1tLbAVL0Bl5AscuLyxVEy6nGNj+srAjyd6kuSwf5gynIY41yN2vsIP9HTjm6+79rKsPresCgHsr3urqbThLM+nZwOYtwpG3pUlgsDLzOHjC4B84+dEhgHACoCBCymHJ6Xs5Cyl9YFXoJ1kuusloQ0QhhovWeqlkZQKVmDpa/N4cE0/p89WDrPMzpoy2LKFl/4uho2rHnGg9SXSyIaAIRzSeiRUR0dUC8rxERE9FY+7mKiO4noveJ6GMiSu20eNBuUEZfjXWJjLS8zppxFm4pDr2NO/yKP11q/ZMFeSIL5iy8cJo6zvosp9Fd6RqkwHewZ/9uuOiLwyOV71h9OVCV4nAMqvo5EwUzh+osQi1dQjI4YV8zd9dhVldLbzkV/bt1wiF79MbSW04Nzks7k5ibzoqcRUUAZ9GpqgIXHjXMylMyuLAerD+jh/T0vFc6aGRZ+CrG9/6NegL7t2eNAQB8cWQ/P40A/nGJdejVqVuH8DobB0RUAeuypJMB7AfgXCLaTxGvG4ArALwtvP46gBpmPgDWvdzfs/1RJQ55sZCtVWSRVElMZ32OCOOxP31tK6hN21qERcSbd5DprKqq8u6oUpAJh8Ncwa2DQ59uUaiuyBns/Mg3IbNHYOG+deI7H3pQ/+fzQdyJnd6gCVLnLNg92Oj2XnFlWn6o1GJHremslIfIWcgWaHJ/FbgjRXsX+sA+EOeM64IlX4EbYeSZC3mQrwwv1+xyFhEh6fnkOhn1dxkU2jLS5CzGAVjEzIttZfijAE5XxPs5gF8BaBbeMYAuRFQJoBbWxUtb0iDSf/mPHsX2l6npbPfaKq2iMAq+Nb4OA3t0wuljXPcQ3WorsUefzuhka/UuOtrdYQfNYzWVOezWvQZj97DOQIiiDFM44qVQBbeCEL+duXroVutkChKScrx2lOB59+dn7A9AXb/TDhyIPl2qcd5h6guJRISRFuQ3KQqS9MjqrN3FLDo1lSJnIfW3TyRkux4PKI7gnYhV1c3nXY5BnrR9/s9CJoDBvYLPEcmpnTq6nEX7RpqLxSAAy4XnevtdAUR0EIAhzPwvKe2TALYBWAXgMwC3qu7gJqKLiGg2Ec1ety7egXI/ZyGZzoob7QhXNBYD+Si/WH44XAqH9umMt6453uNeojKXw2v/fSw++fnJWHrLqTh51EAhpSyGcp/n33Qy3r72hEjnKsJaSycuMdl963QWJmIokH8yCixSoQgmMH42cX88eKFrYXPcPt76iHb5g3rVYs7/nojh/bqGjqEwMVTYDe2mVjliLDnHc8eF6yk8NCn1Ad69dM/aal+4CLHe8mLuW9gKdSDxUUGDa6Elc4cs2W/5vq/CImL21R8V5rJfyt6po+XwMSz3js1ZqMW6TqDF4/0OllNCGeMAtAEYCGAYgB8RkU/IzMx3Obf39evXTw42QhSdhWl3RdNDqHUTIlUk/TWGXbdcziytb7EI2bUFPQeQEzqZqfpEPt+g4wysXXd4n6rS++vE2jDAOijmh39yAqKJltK3obfq1ZrXnxyK8FkAsK2mwMq7XBxRUNi3JvaJvGDK/eUITFX3kYt1cgxYCOp2zbObh9xHucKYk8vWtFmYTkNK5pRX0Ge1gwUhCObbxOioByBuTwbDe+q7G4BRAKbbnbg7gMlENBHAeQBeYOadANYS0ZuwvN4uTppI2RoqyOssKGxPFx3q1Vo9aILG4g2n7YfmnXnQK/6w/t064Yg9+1g94stErGs8nDtuCMZsXQIskXOWuTbvs64+Mh0XHjUMR/boCrzsvtMruE32P+Tbqcof6pghPdGzU4XNG/vbiMA4OcRfEGl+66y9zjtsKHbrFuxF1UuFGkeODN44OZNf367V6Nyvi/JUvexgMgwVRJDNKGqqKkCtbj5tHNzmuYDFQqezcN7qzErzeXfU6RTcORWrBb/pbCgYOGvsYDw+u14ZXF2Rw7F798Or89d56DFy3dHBdRazAIwkomFEVA3gHACTnUBm3szMfZm5jpnrAMwEMJGZZ8MSPR1HFrrA8nL7SRpE5ktgOxvUzepdpG4no8/pgiOH4ZJjRkhvrXTVlTncfvaYUDq9ZYWwhgJu/uqBOGBQ+D0LZLpdlaJd9+X9cOze/T006T6wipzZOVk1Z+EWPKhXLf52waGBeXRViAs9C4QoLzf40s4/bA9cecLI8IghULlL8cLhOAkXHFmnjBH1s1DVb/+BjomyrauKwK7I/evTJ0h/d7d9b910xighFhcWPUvB7S8nz2JeGlGX77W+Hr/6msJVODum78Bt5x5UeF3gLIzEUOVHaosFM7cCuAzAiwA+BvA4M39IRDfa3EMQ/gigK4APYC069zHze2nQGUUMZfLBA9FMZ5WLBanzMNqAFMH7+MVQ+gJNRCVyDJb+6kRJ6j7xxtXpJkwV1zoFubo0f32DSjHuZ1+c0Ch2AcXNLOKGWVdk1I2sq+D25iFaQkX51mTOUd2v7k2A/RUcGQFoE8pUcRYeDkoKjmz9ZBBRpMH56TLD5ecegpCmGArMPAXAFOnd9Zq4xwi/G2GZz6aOyooc9t69K2Crz4NNZ83k4TKCUqhl2WrOIjInyt6aqPIWH028zuq/d4N2kRLfePooTBw9EM2tbfjhY/MK701MZ0cN6oGayhx2tHrN2SoMDpqByDf5iHXfd0B33HDa/i69ZG5iqmu/LwjKT131xP79yYR9MH54+NW1OiqCkCtYpbn/ixgzpCeuPWXfSCWq252wW/dO6FLbDW1rVGIoC09degRmLN7gy89Ds8YgwSnT4fLaPHoYQlueFePa5TascxZuiId6iraX7qc7h0W6EiyEnXfRpywtPvcnuHvUVuHSY/YMjwjzyVo3VSknGpWCWxM32UswSw+XsyAM6lmLft1qcPIBA/CVgwYr43kgHwYkwnWn+ic0U2+0QWajP5u4f+AdCWFQ9Z2J40Oxfy85ZgQOGqp31Z4UVGPq56ePQm/DC5YctCr8fhFZPqp6dK6yNmGaVfKgob1836DO2s0BM2wFt/XsLC7yRkPkHFR93sas5SCiWhabLC5KQUKE0/3lxOd+sQC8IgK/gluIl0rZpi/NFiuTXbWcwoHfN054ef5cRMQb/ibSCiIoCTRVcPvKFH779SHkO2VrIu7rrnFpLd/VUCjFuL2j9nFQXCdHN41OHxTknLBJ4SWAQICwc/frQfR0hil9nYWnYDprR/eKlSzRl0NBTqorg9DaxkJzect0zuwk+d2LkgSHVuvq1wT7NCWkKobaVWAuk7T2/FHRuboCPlMRGyZem2RlXhD27N8VWO88CbQazMAslaHadepzMRFDuSKjoLEf7BvKEcl5qTvn0CHoUlOJgT07GU3kKsOGnrVV+Mlx++DgoY6XWTfOkN6dcdJ+u+G1j6yjQ985algh7ImLD8eGxhYPfVccPxIn7rsbTrvjDV85J+2/O3504l74zdQFUt1Kg8J5A/abzl598j7Yd0A3ZbonLz4C0xestbSQEg7eoxfe8Vm7OQurhShKczPRjNveTvw8e/m6goKb1CJfT3zh8/7hCXvhqMpWYJVCfxUyvv7+nXFGs4SjT4l7kdFBQ3vi3c8aYqWNg4yzgHfisoYOSc92PGFHEgQx/It79UPgdK8aKJrDfyZK0trQ072yzkJd1yQg5+auAcEnb9UfmkIsJ7z66cT98b9f3k9rUisnlE1D2eYeLjlmhOJwlvVHXCD6CxdKHVrXGxNGufdNMICLjx6uvda0Ike4/Hi/1VNyCu4wvYqbjTymLz5aUX8bQ/t0xrcOr1OGqRTczubKOjdEHmWzWKYyP+G7OGJEH184S+ldMZQ3Xpug0lKV1ppXcxZXnjCyYAShOsuhhJ3RF/fq57ljRhHFotUmVuZ4THHyqOA7X5JGtlhEwIAeJjbwXoRJI804i5jSTKWCO0pZEco1imqWX9BcqGstR/xkegBRpUT3tbM8uZmIxwp/KQarUHpRQ5I+CXQCTnFxMoXusiMHrhjK5TQBr4Lb8f3k/HY5HZeQfJ71J+I13RG5zTQWWc6YHWh4wVRAtiVBJoZS4NxxQwCFoe6tXx+N15ZuBz0TnD7KDoFyZJ1V94cY5yGXHheRTnDH0J94L3TyZvDqVcfgufdW4taXFqitoUIKdHaWRpwFoh86A2TxWJBAjmyz0fLLmZ+/8gto2L4TeCA87gPfVV+iZQSF3y9Haksw/yaeuPhw1FaF+/fKs9vOgGt+KoswPQpuBQkWZ2EHqBnKUPcq/hRmMer6dsHvzh6NY/fuj5/84z2jUl750dH4bON2AO4I3H9g+BmnJJBxFgocNky8RtNFry41OOOgQZGUTUQhO2WVFEqetOOazqp0FiEnuL2hfsJ1+gSz3ZZgviiRMaxvFxxjH7wLnsdFE0h/gxiZzipEIoCqo1wTTOcpkulsxP5KTIcpZLTvgO44XBLjOJOf1d/u7y+EnPwOLdbOq+DK39nJk38hccqUcWhdb4yS7hsxWXSdHbt1yE4wnWXHBYnoddalN59nwfeTvFlSlxudYXRTyHqTrxw0GD07G1ie2emG9+ta+E4cHBnmkyohZIuFAsV+tOJHUNenS6CXUOWHQOpJae/d1IrHpOB3JOhH/+6WKM70bmZv/m4ZI/v76yIqXv0I1lk4MFUWqoowNbsNByFHFNnVeKn5EPbvDorPE+Tu4J39CdQLQxBqPPfGK8phyVJREEOJyHs4C39GbcJ9FooR5sk7FEUevPw8+4baJeF0WB5k78CEDiz0dHCnOge+rv/yfvjG+KGoWlELrFHHNTuUZ+G2cw/C3M8acP5f3/YncSsg/FaJTWReW+QsvHcSqCg77cAB6FSZw/E+j7FmOgCCJe5QnSEwmVxVh9722q1r4V2l4aE8v4Ib6NNVMnWVuDFm4YMO4bDIQGXx5MWHo/djVUCTU4zhZFG0sNrfhsVPVK6uoGBmTM6OXl1GUJl9u9bge18cjr/8W+0OzjE1dVzIBFlDFb7igrSJPeE6dzoqHccz3z8Se856USmmNkF8J5H+dMy6kHSQcRYh6GN4O54Ixy//USP7oqayIvBwT5TB07WmEkeNLA3LqQMR4aT9d49t7gdY4g6lXyU7yyhuIQDrxLED0918q0LWFSbuCLWF9+QVvtEcW9fb6/7BOPdkEKU+UeC7TTHmBHlEgHhFlqo6TKHsviPvUS7782nLBzgSVJQ7ekhPdKlOfo8dZ/0v9F+JBk62WEiwdtcEdQ84gyq4d3rbC4zJhKo70Rk2dnRmmdEPbHk5C3VIPMjpLbGHPteCGafabhgAMLhXrfzKAzPfUIThfbt4aQusrSsPd0kLUnDDPgcSUQxlHD1qH8vB/gWqaM5C6LSxdRbXWJHLAcy2ZZN/TIeN8aDzNswMrzLd7aPCO6Dg7gPwL2IMkjYNUriCswhGcW0Y2AeKPnU5i9KsFtlioUCxTT+yf1c88/0jMaKfLR6xO/Xubx3iL8tohvAO1ld+dDRe/MEXo6Uz3Lp4FbQRdtJGUYOvJXTFFXpcduwITPt/3rqLVcvlCDec5ru914fTxwz0uwvRKrijQxR7mKcpFW9hK5w5ykQYDof6X37lADx3xVHoZOsdEryQT1GmJPryHDRktLE3nvy7Lc+Fca5zFunvl/ims2mgVIe7M51FCsjlchgtiEYcqOypdYtF0C5jeL+u2rBikLaCzf4kteEmYqjaqkrsaSvH3QNlXpgo34kIh+wRzfeSqYttx6Qzum+haPHjgrQPxYNBqKnMCe7JrXZIemzJlmlOWwcpuFWwLoBS0xa5P4plzmKmy3QWZQLDvd8XgHfEGCq4fQiIvu8AlY10EeIg1nETJgpuKSjS6A1XcA8JmcQLC6eh6ay2YcImdfKLJVhlsyMruCFMUJoiPO5IDGabWLqfIk9wexTcLL+JC/bU3f4BcUqPouAWaVK14xD7vmvnLnmt6azgddZxTuh+xZLprFSMe+OhZlyYIpFdgEoMlS7HIiNbLBQovm/NMzjlgIHK96UdBk6ZhDGD3R1hkjvdN68+DofW9Q7RWViIeigv7jcT1bQ1CmcBmI0C0Vy3o3AWqiyLGc+q/CYdWYcetdUY2tvSPbmLhbck5zzNIXv0KhieiLA4C3jySJZSc0TlvrRHp1JCJoaS4O8w8v9OsHeUA9QnO43yqam4CQSMLO/u2usRNW65Ts7uO0s0FJyfkatmYTJwd6xRdQ3OjlFKEXYoj737ZHXOos4nhAw5rblzqLCMgoMLOgsumJ4mo+B2zYadkqxGU5cRWmZANasqcrZDKq/OQiWGYgCdhVPh8vfkMkIyfYVamBOWFlQKbieoIyi4iWgCEc0nokVEdHVAvK8RERPRWOHdgUQ0g4g+JKL3iSi6Y6aYKEIItEtDd4+xCZJoJecOhdPHDDKK75z0lU+0mqL4nWQwIltDpUSHrhxOqVDdorefxptteH7hcXIFR4Leidxx8NhZM7bPGjs4lLMoRb/EWX4OrbMuxxo/3O9oMQ2kxlkQUQWs61FPBFAPYBYRTWbmj6R43QBcAeBt4V0lgAcBfJOZ5xFRHwA706JVhKOcZCK4p3kKhDk/PGmO26c/sFAVzwCaQ3mxd3pR5dlC+Q5LH0haBET99HrUVuHjGydo7nvwp9t3QHd8dOOX0Dmq3bujsxCKMTFb9JwaDjLr9CaLSlY4ivU66zGdjamH84GF/wsFFd7sO6AH7jn3UOD33hTXnrJPEWX6FdzindoA8N2jhoHf7Yqcwt/UiH5dcd5XD8Tfnlpuk6vmuo05+1TFWP6ww0f0iTf+YyJNzmIcgEXMvJiZWwA8CuB0RbyfA/gVgGbh3UkA3mPmeQDAzBuYWelurz0gVElZJNdaKq+zROQV8xSp4I4Tp7a6IvAWOzkP5YdiqFvw7ySDFZkmhwWVewtDlMfxYPKms6oycqS+LbA6wMWK2aFBK05BZ5F3xWFgy0lgTognpqmoyHl8ifnPYVjwLSJRlWQpKqJLtVAA6S4WgwAsF57r7XcFENFBAIYw87+ktHsBYCJ6kYjeIaIfqwogoouIaDYRzV63bl1ihMuOzMqB8viJKUGZEWbQ0YN7uGawKYiMxMnB5BrR/Q3HhavgjiiGKnGXMyff49pxq6nceMVdFQ4cS8GvHzIkNE/R3YdLixkKvJVmTTDvl2IV3O0baS5LgUYRZF1Y+zsAkxTxKgEcBeBQANsBvExEc5j5ZU9mzHcBuAsAxo4dm0hbL/7lqUAuh9aCDX8CCu6oY0hzOMgM8RXc1k9RQWvepGrupziTw2cuO0qRZRIcjC2Gsqs+tHdnjK/rA6yVNxxeFeegnrVYcvOXgZ/pyyhKwW0cMyEFt2DuWry7Kf+te7KCW67hezd8CajVu9ce0KMWS285NbRcwK1ym4cO4XtVGEa4ae2/knt7/bJTBtPZUu8kFEiTs6gHIG4JBgNYKTx3AzAKwHQiWgpgPIDJtpK7HsBrzLyembcDmALg4BRp1SJWFxWtsyjXLqMUqv24uabHWSTtI0nnXiIUJZoP0ixGzxGnUarAWTgK7hj3lDgcoDwZRnanUeSEbrlSb79Ic7GYBWAkEQ0jomoA5wCY7AQy82Zm7svMdcxcB2AmgInMPBvWLb8HElFnW9l9NICP/EWkgMIEouAi4h7KE3DuuKEmRHhOIeeIMemIOrMCijiUJ+/AIm03TW6eS2RSNsgj4qE8LpgFaTgh1RgwuNcjMkNpmiLJQ3kFLqN4BbevvwsKbg1Xm8hu2cr7iBGW08FvjN9DURNv3zp0jujvnNHQ0KPzDVXqK+r+f3tnHiRHdR7w3yetWGklodUiCR3oNELmFIItxGEwYCOBMII4shE4gIEqVSVQBsquADG2OaoMwgngFNiBghBsKDC2ASsCgoNiSOQKIIFkkBAEcZnlCCIGURJG6Pjyx+vZ6Znpnj6me679flWzO/3663f06+nvvfe99z0vF40mN2WhqjuAC3Ev/g3A/aq6XkSuFpGFEdd+CNyAUzhrgedU9eG88lpPrv3qgbHkHr3o6P7vQzsGc+XC/fPKko+ynkUTdH3zJOK9n1n8ecnXimr71PH4UUN547qT+6eTxmHM8FJnnGEGbsORqyldVR/BDSH5w74fInts2fHduOmz9SXAM6XvZKBMQCRJEgzJQ9ofcdLx7KCeU8WZVARen/bllOlLTUqiVPfWjJQvJc7U2YQG7tiStdks/O5LijHWeH/7F96VJFTWO6vy7KUh7v0Nk+vvOTgGSXnbOaRnEZ5QTLlKShd8BkXdeKVu7j5CGOwZu+q14KU6ads4SYeUyodi4qc7pafS79OhU8ucKWbRhM/EwO3w+xMKjjvN+Hd66tXKH5T4uYhHaO7zHLYJiHtoh8tJyQ6VJQbu0mvm7e828jpzbumsq3D3LtmX55ITZtLdNSRasIGYsgih8CIp2R83rs0ig0V5+bUkImwWIaeiCPK7c9bh06LTj02G96PQoiz0LCpWXwbLx89LurxmV8LkMWX1+tPQnmrAM53TIraOQeWu0aunM26kG46a0N1VEt6/n0WtPZgY7D9xFOd9YUa1yFPHnRWmLFqBtIbmVNtvpTXQxpg62ywGbo/KzZYSGDLDDNzJVjKWXRtTsNaWemHISCHLVnL49Ok8R//jPHelYf23uXAfI+5npYE7bt7aC3MkmAs12iwSx5EV2ad585lzePX9rb4kmsFmURpl1r/9tOP/9VrBXbyVebz1qtsHsk0q5/uV+Pbk01NqFkxZhBE05FR0T5lz2uUBSZ7aENlYi/IE1LebXY1TZ1HlK7MnVpdJSibj36WGzf7tXiO8zhYvL7ftZETsx6rWRXn+qDKaOqtBMUjVRXmZvBwDOxEBU3ir2CzC6rkQWjn80oCuhRm4jeai8Q9kXcm1hZ2cJngfGEYo1rMIpVovookN3DV4naXgaTczgiJrHgN35aK86vIleanmddZ36u8WfL5/wVhktmJJkbyOY0STxaK84t9CNvw9sPoZuGPLReSn6OMr5o8iHzfNcU7WBVMWrUDaoZeEXmcrX4IZDH9lTpYGbkfR+VztK3XLXyxLjvlc/Gvr1LUoGOHrY+DONo14ccc0cPefijBw1+p1tk2wYagwqk2TbepFeVHJQboKpAAAELZJREFURdgs8qaJDNyFKZaju3aLiD9Zizi9gTsjktgsPHKZOhv5bNXaEs96SmtZzyKxr6Yce0pNMEZpPYuWIG0LP8002pRTb0MM3JEySclwUd6oriH88C8O5IuzxsKKuxPmL2TqbA2v3fjvg9ruY2F2r6LZtZJVmTGmi1G7jaoIr/eivKiw/joK61GWhebj46z1MGWRBxl4nW1MS6IeaTaBzcLHmXPjOHZMRrNPnc0rmc6OwUzsrlzJn1+i9Z5qnJVgTtfnjA1DhVKDgTurtAtksigvJI5qXmdrtlk06aK80DoN6QklMHDX8mRktygvahgqyGaRhYE7YMpqnbzOVg8rTydkkV1Zfgq70I0aVuaGw7zOGkbjH0gjfxqzfWvrceBebmOm03tDduobYJiyCKNaqyfyt9ZIA3cNC7ay7gYHtcCawsCddNJCUIu4ytTZVHnK0GYRM6LSPmSN9zewFyZl4VUmV6Sh1uGhCJ9f4nmh7eyocYpubJrbwG3KoiVI+/pJZ+CePmZ4wmtiyjaZgTs67tqnzia7tj4vhD1GuGGVqT1d2Q6phMXVdAbuipNJE00o3x7kqixE5EQReVlENorIZVXkFomIeluq+sOniMgWEflOnvkMyVUhE+HnQi+t1cAdsIApM6qMG3vff/3XR/LQBUfVJ/3crwuKKmGdJvA6O3ZEJ/MPGJ9dttLFVPXs3Ol7cNd5h/E3x+3dH5blaovi17JeRrMtyqsQq7HnE7M8j118DCsvPS7h9Y3vWeQ2G0pEBgO3ACfg9tReJSLLVPXFMrmRwLeApwOiuRF4NK88tgx5GrgDru8Zvhs9w3eDP38YP91WMnDHjTuF19nB4q3bSEH8Uaga76MqX9xnbG1xVEZK+DPQbIvyyqbORt3PjKeAzxo/sqbrG0WePYvDgI2q+pqqfgbcB5waIHcNcD3wqT9QRE4DXgPW55hHo4TGt14GMu2yxanRnuSpLCYBb/mO+7ywfkRkDjBZVZeXhQ8HLgWuqpaAiCwRkdUisnrTpk3Z5Lo/8oov/oTjXpwkobL4/eEZLsqLXMGd86K81KNQkiBPKaaWBvrFqjbdOCwNDY4/BvGvqtXAXVnHmRi4K7an9e5pf3jWBu6QKcwVXmdLw+J6nS2WJW4POU8Dd41RZ0CeyiKoeP13WdxUgxuBbwfIXQXcqKpbqiWgqrepaq+q9o4dm3W3eiDSBE/kAMY6FkYzk+cK7j7AP0F5L+Ad3/FI4ADgCa/7PR5YJiILgbnAIhG5HugGdonIp6p6c475LaNFDdyRDe9oA3d2BGWmTQzc1Xo4Ke9j7GGopHWcRZSxYwjrqTahgbsiPyHXxe1h57qCu/EtiTyVxSpgpohMB94GFgNnFk6q6mag33eziDwBfEdVVwNH+8KvBLbUV1G0Cam8zqZOLCOZDKiHgTvztOtI6lX6kRFnGFctaYaHrbtqPkP+6w+w0n8qYb5boY5zILdhKFXdAVwIPAZsAO5X1fUicrXXe2huzOtsndLP+brgyBLGn7RF3OBWYIrka9/PopB2mc2iJDwHm0VCuRGdHXR2DA4TTBd/2PWJSdK7rT+5OhJU1UeAR8rCvh8ie2xI+JWZZ6wVqTAehgoGfzevsynirhZPNQN33tSaRso6rhqlhj8DTbYor7/8EV5nK+RDjwcGtoLb8NH41othGM2JKYtQmszAHbd1FrkoL8LAnel4dlCLrFYDdwaL8nL0Ohu/B1gDtW6rGlDH2WyrWla/Uhaei4E7js0iYkp41LTyuD3kNjdwm7IwfDT+gTQMozkxZRGGGbjrlH7O1wVHFiso9GTTG7gbMXU2KO3mM3BXD8+655OU5jZwm7JoGVIYqBMbMqt015P6zwkKaysDd8Zp1zUNM3CXhpmBOw6mLEJpMptFZkTYLHKn8S2kPL3OhsdfT9Kkn1WeqzxPzbYor0Ksxp6P2SyMpiAzA3eSdJK0QOMYGrNokWVg4I4bdwqvs3VZsJWB11nfQW1xlcQT9gzkeU+SLcpzX8t6FHX2OtuqmLJoS2qdcWQYhlGKKYswms7AncBmEeQts2avsxnZLGo1cOfqdTasJxQ0fFJtUV7eSjfN1OCQ63P3OusPz3gYKszrbKRcmM0iLH9xe8jtvYLblEVb0vgHyzCM9sKURSi1GLiTJ1MRWEtLIq2fo6Y2cGeYNzNwV5DdKHzY85THpA0zcNeTXH1DtQxDhgcE+rumZcMOUqZjh40uu7asYod7e20MDtpuM+Yw1/UzgmXL2bYZOobCrh3wkyOLed21Izhuf1lkEGx6Ga6d4o51V/Hc0mnV09+5rTLst1fAimuKx9s/ga6e6DIEUcjn41fCE9dVlw3KS2lkwfFvea9YdvCVP0DBrrod1txTGc+2zcHxhzFiHGz29gjzp12N7Vurn496ad0xD8RzprfDbVCZaBiqeyp89GZp2J0LXP1OPsyXD++ebn0fph9D5i88GQQvLQ+/b8N6inKvPVGU2/Fn93/N3bDugeJvo6KevWfuoQvgXy8phofe/5DyDely/4d2h1xXll7gOVMWzcE+8+GwJTBxTjFs/rXw7lqYvdh93nu+eG7eNdC32oUNGw0nLYVDvwkv/sa9YGYvLo3/q7fDhmUwbl93fO6j8MErsLkPJs+Fsx6C/77ZXds9FfZb6B6Ok2+AXTvdD3PXznhlEYGZJ7gfx47PSs8NGQZTjywNG7EnfPlK6BwJ42fDyIml5z9+Gzo6oWsMkbz3Akw4CHZsc0pn/IGVMpMOiVeOcobuDvN/CB+9FS0LMHJPmHUy9K2Cz7ZC9xRYfQeM2QcO+nqlfO957v6Uj4F37OaeDz8nXgvvPk8gIjDnrHh5BFh8Lzz1E9i5vVQ5RzF6GnzcB5994l7GXXvA/73qnqdJvZXyX/85fPRH+OQD2F6ygzFXr9zCVobFT3vRnbD2bvcSnHEcvPl72O69gA/6WlGu9zzXcFGFWSe5e3nSj2DNz2DO2fHTC+P4K+CNlQEn1D0np/zYHX7xUtj4eKnIe8/D+IOKx50jYNKh7rfYubsL65kBx30XPvlTZRI909397BgKUw6H1/8TZi0IzuesBXDiUjgk4rnY9xTXcNixDRD3/YgLXNyTDq1+bR0QbZNpYL29vbp69epGZ8MwWo5plz0MwBvXndzgnBiNQESeVdWAFkYp1rMwjAHOTacfzLiRnY3OhtHk5GrgFpETReRlEdkoIpdVkVskIioivd7xCSLyrIi84P0/Ps98GsZA5rQ5kzhy7xjDjMaAJreehYgMBm4BTsDtx71KRJap6otlciOBbwFP+4I/AE5R1XdE5ADcbnuT8sqrYRiGUZ08exaHARtV9TVV/Qy4Dzg1QO4a4Hqg3+qmqmtU9R3vcD0wVESsn2wYhtEg8lQWkwD/1JU+ynoHIjIHmKyqy6vE85fAGlWNmg9pGIZh5ESeBu6gicH9U69EZBBwI/DN0AhE9geWAvNCzi8BlgBMmRJzjrphGIaRmDx7Fn3AZN/xXsA7vuORwAHAEyLyBnA4sMxn5N4LeBA4W1VfDUpAVW9T1V5V7R07dmwORTAMwzAgX2WxCpgpItNFZDdgMbCscFJVN6vqGFWdpqrTgKeAhaq6WkS6gYeBy1X19znm0TAMw4hBbspCVXcAF+JmMm0A7lfV9SJytYgsjLj8QmBv4Hsistb7jMsrr4ZhGEZ1bAW3YRjGACbuCu62URYisgl4M1IwnDG49R0DCStz+zPQygtW5qRMVdVIo2/bKItaEZHVcbRrO2Flbn8GWnnBypwXtp+FYRiGEYkpC8MwDCMSUxZFbmt0BhqAlbn9GWjlBStzLpjNwjAMw4jEehaGYRhGJKYsDMMwjEgGvLKIu0FTqyEik0XkdyKyQUTWi8hFXniPiPy7iLzi/R/thYuI/KN3H54XkZSbZTceERksImtEZLl3PF1EnvbK/AvP/Qwi0ukdb/TOT2tkvtMiIt0i8isRecmr7yPavZ5F5BLvuV4nIveKyNB2q2cR+WcReV9E1vnCEteriJzjyb8iIuekzc+AVha+DZpOAvYDzhCR/Rqbq8zYAXxbVffFOWm8wCvbZcAKVZ0JrPCOwd2Dmd5nCfDT+mc5My7CuZgpsBS40Svzh8D5Xvj5wIequjfOA/LSuuYyO34M/Juqfh6YjSt729aziEzCbZjWq6oHAINxvufarZ7/BTixLCxRvYpID/ADYC5uj6EfFBRMYlR1wH6AI4DHfMeX45wXNjxvOZT1N7hdC18GJnhhE4CXve+3Amf45PvlWumD8268AjgeWI5zlf8B0FFe5zi/ZUd43zs8OWl0GRKWd3fg9fJ8t3M9U9wrp8ert+XA/HasZ2AasC5tvQJnALf6wkvkknwGdM+CGBs0tQNet3sObuvaPVX1XQDvf8FBY7vci5uAvwV2ecd7AB+pc2wJpeXqL7N3frMn30rMADYBd3pDb7eLyHDauJ5V9W3g74E/Au/i6u1Z2rueCySt18zqe6Ari6obNLUDIjIC+DVwsap+XE00IKyl7oWIfAV4X1Wf9QcHiGqMc61CB3AI8FNVnQNspTg0EUTLl9kbRjkVmA5MBIbjhmHKaad6jiKsjJmVfaAri6gNmloaERmCUxT3qOoDXvD/isgE7/wE4H0vvB3uxVHAQm8zrftwQ1E3Ad0iUtgV0l+u/jJ750cBf6pnhjOgD+hT1ae941/hlEc71/OXgddVdZOqbgceAI6kveu5QNJ6zay+B7qyqLpBUysjIgLcAWxQ1Rt8p5YBhRkR5+BsGYXws71ZFYcDmwvd3VZBVS9X1b3Ubaa1GPgPVf0G8DtgkSdWXubCvVjkybdUi1NV3wPeEpFZXtCXgBdp43rGDT8dLiJd3nNeKHPb1rOPpPX6GDBPREZ7PbJ5XlhyGm3AafQHWAD8D/Aq8N1G5yfDcn0B1918HljrfRbgxmpXAK94/3s8ecHNDHsVeAE306Th5aih/McCy73vM4BngI3AL4FOL3yod7zROz+j0flOWdaDgdVeXT8EjG73egauAl4C1gE/BzrbrZ6Be3E2me24HsL5aeoVOM8r+0bg3LT5MXcfhmEYRiQDfRjKMAzDiIEpC8MwDCMSUxaGYRhGJKYsDMMwjEhMWRiGYRiRmLIwjCZARI4teMk1jGbElIVhGIYRiSkLw0iAiPyViDwjImtF5FZv74wtIvIPIvKciKwQkbGe7MEi8pS3v8CDvr0H9haRx0XkD941n/OiH+Hbl+Ieb3WyYTQFpiwMIyYisi9wOnCUqh4M7AS+gXNk95yqHgI8ids/AOBnwKWqehBuVW0h/B7gFlWdjfNpVHC3MQe4GLe3ygycryvDaAo6okUMw/D4EnAosMpr9A/DOXLbBfzCk7kbeEBERgHdqvqkF34X8EsRGQlMUtUHAVT1UwAvvmdUtc87Xovby2Bl/sUyjGhMWRhGfAS4S1UvLwkU+V6ZXDUfOtWGlrb5vu/Efp9GE2HDUIYRnxXAIhEZB/37IU/F/Y4K3k7PBFaq6mbgQxE52gs/C3hS3Z4ifSJymhdHp4h01bUUhpECa7kYRkxU9UURuQL4rYgMwnkDvQC34dD+IvIsbhe2071LzgH+yVMGrwHneuFnAbeKyNVeHF+rYzEMIxXmddYwakREtqjqiEbnwzDyxIahDMMwjEisZ2EYhmFEYj0LwzAMIxJTFoZhGEYkpiwMwzCMSExZGIZhGJGYsjAMwzAi+X/ipge6p3g7LQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#summarise history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
